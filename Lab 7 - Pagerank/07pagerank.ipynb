{"cells":[{"cell_type":"markdown","id":"1a1defe9-0d69-429b-9dcf-79cf72b20e31","metadata":{"id":"1a1defe9-0d69-429b-9dcf-79cf72b20e31"},"source":["# CAI Lab Session 7: Implementing Pagerank"]},{"cell_type":"markdown","id":"8efc4b56-ecee-4b48-bea1-8a3a28983a3a","metadata":{"id":"8efc4b56-ecee-4b48-bea1-8a3a28983a3a"},"source":["In this session you will:\n","\n","- implement an efficient version of Pagerank on directed graphs\n","- apply it to couple of examples, including a graph defined by airports and flights"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Pagerank\n","\n","In class we have explained the iterative method for computing PageRank using matricial notation (i.e. the ``power method''). \n","The iterative step was the matrix-times-vector product $P(t) = M^T*P(t-1)$,\n","but then we replaced $M$ with the Google matrix $G = d*M + (1-d)/n * J$, where $d$ is the \\emph{damping factor}. \n","This was done in order to guarantee a unique solution and its fast convergence to it.\n","\n","In this lab, we assume that a graph $G=(V,E)$ is given to us as a table of vertices + for each one, a list\n","of successors. This is known as the _adjacency list_ representation. In cases where we have significantly fewer edges than the maximum possible (e.g. in a graph with $n$ nodes we may have $O(n)$ edges instead of the maximum $O(n^2)$ possible. In this case, the adjacency list representation is much more compact than the matrix. Additionally for very large graphs we may not even be able to fit the full matrix into main memory, and would need instead to process few adjacency lists at a time.\n","\n","An efficient implementation of the formula using an adjacency list representation of $G$\n","instead of a matrix $M$ would be:\n","\n","```\n"," 1. n = number of vertices in G\n"," 2. P = any vector of length n and sum 1 (for example, the all 1/n vector)\n"," 3. d = the chosen damping factor, between 0 and 1\n"," 4. while not stopping condition:\n"," 5.    for i in V:\n"," 6.      L = [ j for (j,i) in E ]\n"," 7.      Pnew(i) = (1-d)/n\n"," 8.      for j in L:\n"," 9:          Pnew(i) += d * P(j)/out(j)\n","10:    compute a distance between Pnew and P (to be used in stopping condition)\n","11:    P = Pnew\n","```\n","\n","__Silly question:__ How do we know that the division by `out(j)` in line 9 does not give an error?\n","\n","The stopping condition we propose is that `P` and `Pnew` are sufficiently close\n","under some distance you need to compute. \"Close\" is up to you: 0.01, 0.00001, 0.00000001, etc.\n","\n","The damping factor $d$ is of your choice. Popular ones are between 0.8 and 0.9. Something \n","you can investigate is how different choices affect the solution and how they affect the computation time."]},{"cell_type":"markdown","metadata":{},"source":["## 2. Pagerank without inverting the graph\n","\n","The scheme above is all fine for graphs that fit in RAM.\n","But this need not be the case. It is not uncommon to have graphs so large that\n","at least the lists of edges have to be in disk. And, most likely, \n","we will have a list of _outgoing_ edges, not _incoming_ edges.\n","\n","In other words, the algorithm above uses the list `[ j for (j,i) in E ]`. \n","But if we are given $G$ and not its inversion, what we will have instead is `[ j for (i,j) in E ]`.\n","\n","Given this, we have two options:\n","\n","\n","1. _Invert the graph._ This is similar to the problem of computing the inverted index.\n","As it has very low disk locality if implemented naively, this takes time.\n","\n","2. _Change the algorithm_ so that we compute pageranks incrementally. This is similar to \n","what we did for computing tf-idf: invert the loops, and keep a set of partially computed\n","tf-idfs (here, of partially computed pageranks). Similar to this:\n","\n","```\n"," 1. n = number of vertices in G\n"," 2. P = any vector of length n and sum 1 (for example, the all 1/n vector)\n"," 3. d = the chosen damping factor, between 0 and 1\n"," 4. while not stopping condition:\n"," 5.    Pnew = the all (1-d)/n vector\n"," 6.    for i in V :\n"," 7.        L = [ j for (i,j) in E ]. // forward adjacency list for node i\n"," 8.        for j in L:\n"," 9:            Pnew(j) += d * P(i)/out(i)\n","10:    compute a distance between Pnew and P\n","11:    P = Pnew\n","```\n"]},{"cell_type":"markdown","metadata":{},"source":["## 3. The input files\n","\n","The following two files have been downloaded from [Open Flights](http://openflights.org/data.html).\n","\n","\n","- `airports.txt` contains a list of airports from the world. The first fields are: an OpenFlights airport identifier, name of the airport, main city it serves, country, 3 letter IATA code, 4 letter ICAO code, and other stuff. (Only major airports have IATA codes). As an example, the first two lines of this file are as follows:\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1,\"Goroka\",\"Goroka\",\"Papua New Guinea\",\"GKA\",\"AYGA\",-6.081689,145.391881,5282,10,\"U\"\n","2,\"Madang\",\"Madang\",\"Papua New Guinea\",\"MAG\",\"AYMD\",-5.207083,145.7887,20,10,\"U\"\n"]}],"source":["!head -n 2 airports.txt"]},{"cell_type":"markdown","metadata":{},"source":["\n","- `routes.txt` contains a list of routes from the world. The first fields are: an airline code, an OpenFlights airline code, an origin airport code (3 letter IATA code or 4 letter ICAO code), same with OpenFlight code, a destination airport code (3 letter IATA code or 4 letter ICAO code), then other stuff.\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["2B,410,AER,2965,ASF,2966,,0,CR2\n","2B,410,AER,2965,GOJ,4274,,0,CR2\n"]}],"source":["!head -n 2 routes.txt"]},{"cell_type":"markdown","metadata":{},"source":["\n","Note that there is no guarantee that each airport mentioned in `routes.txt` has an entry in `airports.txt`. \n","There may also be dangling nodes, that is, airports with some incoming route and no outgoing routes. \n","__As you know, Pagerank needs to be patched to deal with these types of nodes.__\n","\n","We provide reading functions for these two files to return a dictionaries representing routes and airports.\n","The way these functions deal with dangling nodes is by simply removing them."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def read_airports():\n","# sample line:\n","# 1382,\"Charles De Gaulle\",\"Paris\",\"France\",\"CDG\",\"LFPG\",49.012779,2.55,392,1,\"E\"\n","    airportsTxt = open(\"airports.txt\", \"r\", encoding=\"utf8\");\n","    cont = 0\n","    airport_dict = {}\n","    for line in airportsTxt.readlines():\n","        try:\n","            temp = line.split(',')\n","            airp_name = temp[4][1:-1]\n","            airport_dict[airp_name] = (\n","                airp_name+\n","                \" (\"+temp[1][1:-1]+\", \"+\n","                temp[2][1:-1]+\", \"+\n","                temp[3][1:-1]+\")\"\n","                )\n","        except Exception as inst:\n","            # print(\"incorrect line in airports:\",line)\n","            pass\n","    airportsTxt.close()\n","# for the sample line, it adds to dict the pair\n","# \"CDG\": \"CDG (Charles de Gaulle, Paris, France)\"\n","    print(airport_dict[\"CDG\"])\n","    print(len(airport_dict), \"airports read successfully\")\n","    return airport_dict\n","\n","def read_routes(airp):\n","# sample line:\n","# AB,214,CDG,1382,VIE,1613,Y,0,320 321\n","# note: there are no \" quotes around airport names, unlike in airports.txt\n","    routesTxt = open(\"routes.txt\", \"r\", encoding=\"utf8\");\n","    route_dict = dict()\n","    nroutes = 0\n","    for line in routesTxt.readlines():\n","        try:\n","            temp = line.split(',')\n","            origin_id = temp[2]\n","            dest_id = temp[4]\n","            origin_airp = airp[origin_id]\n","            dest_airp = airp[dest_id]\n","            if origin_id not in route_dict:\n","                route_dict[origin_id] = [] # empty LIST\n","            route_dict[origin_id].append(dest_id)\n","            nroutes += 1\n","        except Exception as inst:\n","            # print(\"incorrect line, or unknown airport, in routes:\", line)\n","            pass\n","    routesTxt.close()\n","    print(nroutes, \"routes read successfully\")\n","\n","    # remove dangling nodes\n","    filtered = dict()\n","    for i in route_dict:\n","        all_destinations = [ j for j in route_dict[i] if j in route_dict]\n","        if len(all_destinations):\n","            filtered[i] = all_destinations\n","\n","    return filtered"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["CDG (Charles De Gaulle, Paris, France)\n","5742 airports read successfully\n"]},{"data":{"text/plain":["'CDG (Charles De Gaulle, Paris, France)'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["airports_dict = read_airports()\n","airports_dict[\"CDG\"]"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["68292 routes read successfully\n"]},{"data":{"text/plain":["['ATH',\n"," 'HER',\n"," 'SKG',\n"," 'TBS',\n"," 'BOS',\n"," 'DFW',\n"," 'JFK',\n"," 'KUL',\n"," 'LHR',\n"," 'MIA',\n"," 'ORD',\n"," 'VIE',\n"," 'YUL',\n"," 'YYZ',\n"," 'ABJ',\n"," 'ABV',\n"," 'ABZ',\n"," 'AGP',\n"," 'ALG',\n"," 'AMM',\n"," 'AMS',\n"," 'ARN',\n"," 'ATH',\n"," 'ATL',\n"," 'AUH',\n"," 'BCN',\n"," 'BEG',\n"," 'BES',\n"," 'BEY',\n"," 'BHX',\n"," 'BIO',\n"," 'BKK',\n"," 'BKO',\n"," 'BLL',\n"," 'BLQ',\n"," 'BLR',\n"," 'BOD',\n"," 'BOG',\n"," 'BOM',\n"," 'BOS',\n"," 'BRE',\n"," 'BRS',\n"," 'BSL',\n"," 'BUD',\n"," 'BZV',\n"," 'CAI',\n"," 'CAN',\n"," 'CCS',\n"," 'CFE',\n"," 'CGN',\n"," 'CKY',\n"," 'CLY',\n"," 'CMN',\n"," 'COO',\n"," 'CPH',\n"," 'CVG',\n"," 'CWL',\n"," 'DEL',\n"," 'DKR',\n"," 'DLA',\n"," 'DTW',\n"," 'DUB',\n"," 'DUS',\n"," 'DXB',\n"," 'EDI',\n"," 'EMA',\n"," 'EVN',\n"," 'EWR',\n"," 'EXT',\n"," 'EZE',\n"," 'FCO',\n"," 'FIH',\n"," 'FLR',\n"," 'FRA',\n"," 'FSC',\n"," 'GIG',\n"," 'GOA',\n"," 'GOT',\n"," 'GRU',\n"," 'GVA',\n"," 'GYD',\n"," 'HAJ',\n"," 'HAM',\n"," 'HAN',\n"," 'HAV',\n"," 'HEL',\n"," 'HKG',\n"," 'HND',\n"," 'IAD',\n"," 'IAH',\n"," 'ICN',\n"," 'IST',\n"," 'JED',\n"," 'JFK',\n"," 'JNB',\n"," 'KBP',\n"," 'KIX',\n"," 'KUL',\n"," 'LAD',\n"," 'LAX',\n"," 'LBV',\n"," 'LCA',\n"," 'LED',\n"," 'LFW',\n"," 'LHR',\n"," 'LIM',\n"," 'LIN',\n"," 'LIS',\n"," 'LJU',\n"," 'LOS',\n"," 'LUX',\n"," 'LYS',\n"," 'MAD',\n"," 'MAN',\n"," 'MEX',\n"," 'MIA',\n"," 'MPL',\n"," 'MRS',\n"," 'MRU',\n"," 'MSP',\n"," 'MUC',\n"," 'NAP',\n"," 'NBO',\n"," 'NCE',\n"," 'NCL',\n"," 'NDJ',\n"," 'NIM',\n"," 'NKC',\n"," 'NRT',\n"," 'NSI',\n"," 'NTE',\n"," 'NUE',\n"," 'ORD',\n"," 'OSL',\n"," 'OTP',\n"," 'OUA',\n"," 'PEK',\n"," 'PHL',\n"," 'PIT',\n"," 'PNR',\n"," 'PRG',\n"," 'PSA',\n"," 'PUF',\n"," 'PUJ',\n"," 'PVG',\n"," 'RBA',\n"," 'RIX',\n"," 'RNS',\n"," 'ROB',\n"," 'RUH',\n"," 'SCL',\n"," 'SEA',\n"," 'SFO',\n"," 'SGN',\n"," 'SIN',\n"," 'SLC',\n"," 'SOF',\n"," 'STR',\n"," 'SVO',\n"," 'SXM',\n"," 'TBS',\n"," 'TLL',\n"," 'TLS',\n"," 'TLV',\n"," 'TNR',\n"," 'TRN',\n"," 'TUN',\n"," 'TXL',\n"," 'VCE',\n"," 'VGO',\n"," 'VIE',\n"," 'VLC',\n"," 'VRN',\n"," 'WAW',\n"," 'WUH',\n"," 'YUL',\n"," 'YYZ',\n"," 'ZAG',\n"," 'ZRH',\n"," 'ALG',\n"," 'CZL',\n"," 'ORN',\n"," 'DEL',\n"," 'MEX',\n"," 'LIN',\n"," 'BOS',\n"," 'DFW',\n"," 'HEL',\n"," 'JFK',\n"," 'MIA',\n"," 'ORD',\n"," 'ABJ',\n"," 'ABZ',\n"," 'ARN',\n"," 'ATL',\n"," 'BES',\n"," 'BIO',\n"," 'BKK',\n"," 'BLL',\n"," 'BLQ',\n"," 'BOD',\n"," 'BOS',\n"," 'BRE',\n"," 'CFE',\n"," 'CPH',\n"," 'DKR',\n"," 'DTW',\n"," 'DUB',\n"," 'DUS',\n"," 'DXB',\n"," 'EDI',\n"," 'FCO',\n"," 'FLR',\n"," 'GOA',\n"," 'GOT',\n"," 'HAJ',\n"," 'HAM',\n"," 'HAN',\n"," 'HKG',\n"," 'IAD',\n"," 'IAH',\n"," 'JFK',\n"," 'JNB',\n"," 'LAX',\n"," 'LIM',\n"," 'LIN',\n"," 'LIS',\n"," 'MAN',\n"," 'MEX',\n"," 'MIA',\n"," 'MPL',\n"," 'MRS',\n"," 'NAP',\n"," 'NCL',\n"," 'NTE',\n"," 'NUE',\n"," 'OSL',\n"," 'PRG',\n"," 'PSA',\n"," 'PUF',\n"," 'PUJ',\n"," 'RNS',\n"," 'SCL',\n"," 'SEA',\n"," 'SFO',\n"," 'SGN',\n"," 'SIN',\n"," 'STR',\n"," 'SXM',\n"," 'TLS',\n"," 'TRN',\n"," 'TXL',\n"," 'VCE',\n"," 'VGO',\n"," 'VRN',\n"," 'YUL',\n"," 'YYZ',\n"," 'MSQ',\n"," 'BOS',\n"," 'DFW',\n"," 'JFK',\n"," 'LHR',\n"," 'MIA',\n"," 'ORD',\n"," 'ABZ',\n"," 'BHX',\n"," 'BRS',\n"," 'CWL',\n"," 'EDI',\n"," 'EMA',\n"," 'EXT',\n"," 'MAN',\n"," 'NCL',\n"," 'TPE',\n"," 'RIX',\n"," 'PEK',\n"," 'PVG',\n"," 'HKG',\n"," 'ATH',\n"," 'LCA',\n"," 'CAN',\n"," 'URC',\n"," 'ABV',\n"," 'ATL',\n"," 'BOS',\n"," 'CVG',\n"," 'DTW',\n"," 'EWR',\n"," 'IAD',\n"," 'IAH',\n"," 'JFK',\n"," 'LAX',\n"," 'MIA',\n"," 'MSP',\n"," 'NIM',\n"," 'ORD',\n"," 'PHL',\n"," 'PIT',\n"," 'SEA',\n"," 'SFO',\n"," 'SLC',\n"," 'YUL',\n"," 'YYZ',\n"," 'DUB',\n"," 'ORK',\n"," 'DXB',\n"," 'ADD',\n"," 'BRU',\n"," 'AUH',\n"," 'SOF',\n"," 'KEF',\n"," 'DJE',\n"," 'SFA',\n"," 'TUN',\n"," 'LED',\n"," 'BAH',\n"," 'VIE',\n"," 'TAS',\n"," 'BOS',\n"," 'DFW',\n"," 'JFK',\n"," 'MIA',\n"," 'ORD',\n"," 'SCQ',\n"," 'OLB',\n"," 'PMO',\n"," 'SAH',\n"," 'TLV',\n"," 'GYD',\n"," 'GIG',\n"," 'GRU',\n"," 'HND',\n"," 'NRT',\n"," 'LJU',\n"," 'BEG',\n"," 'ICN',\n"," 'ABV',\n"," 'AMS',\n"," 'BSL',\n"," 'DLA',\n"," 'EZE',\n"," 'NIM',\n"," 'PUJ',\n"," 'MLA',\n"," 'NBO',\n"," 'ZRH',\n"," 'FCO',\n"," 'BZV',\n"," 'LUX',\n"," 'DUS',\n"," 'EWR',\n"," 'FRA',\n"," 'HAM',\n"," 'IAD',\n"," 'MUC',\n"," 'ORD',\n"," 'TXL',\n"," 'YUL',\n"," 'YYZ',\n"," 'WAW',\n"," 'LBA',\n"," 'MAN',\n"," 'GVA',\n"," 'ZRH',\n"," 'TLV',\n"," 'TNR',\n"," 'BEY',\n"," 'DFW',\n"," 'HEL',\n"," 'KUL',\n"," 'MIA',\n"," 'ORD',\n"," 'BSL',\n"," 'MRU',\n"," 'CAI',\n"," 'BCN',\n"," 'MAD',\n"," 'PEK',\n"," 'PRG',\n"," 'PVG',\n"," 'NRT',\n"," 'ATH',\n"," 'SKG',\n"," 'PRG',\n"," 'VIE',\n"," 'DBV',\n"," 'SPU',\n"," 'ZAG',\n"," 'TLL',\n"," 'ICN',\n"," 'ISB',\n"," 'LHE',\n"," 'MXP',\n"," 'KBP',\n"," 'NSI',\n"," 'DOH',\n"," 'OSR',\n"," 'PRG',\n"," 'AMM',\n"," 'OTP',\n"," 'PDL',\n"," 'AJA',\n"," 'BIA',\n"," 'BVC',\n"," 'CTA',\n"," 'CUN',\n"," 'FDF',\n"," 'FSC',\n"," 'JFK',\n"," 'LAS',\n"," 'MIA',\n"," 'PMO',\n"," 'PTP',\n"," 'PUJ',\n"," 'SFO',\n"," 'SUF',\n"," 'GCI',\n"," 'JER',\n"," 'ARN',\n"," 'CPH',\n"," 'OSL',\n"," 'BRU',\n"," 'SIN',\n"," 'SVO',\n"," 'JED',\n"," 'RUH',\n"," 'BKK',\n"," 'IST',\n"," 'SAW',\n"," 'LAX',\n"," 'YQB',\n"," 'YUL',\n"," 'YVR',\n"," 'YYC',\n"," 'YYZ',\n"," 'SFA',\n"," 'AGA',\n"," 'AGP',\n"," 'AJA',\n"," 'BCN',\n"," 'BFS',\n"," 'BIA',\n"," 'BIQ',\n"," 'BLQ',\n"," 'BRI',\n"," 'BRS',\n"," 'BUD',\n"," 'CFU',\n"," 'CMN',\n"," 'CPH',\n"," 'CTA',\n"," 'EDI',\n"," 'FEZ',\n"," 'GLA',\n"," 'HER',\n"," 'IBZ',\n"," 'KRK',\n"," 'LIS',\n"," 'LPL',\n"," 'LTN',\n"," 'MAD',\n"," 'MAH',\n"," 'MXP',\n"," 'NCE',\n"," 'OPO',\n"," 'PMI',\n"," 'PRG',\n"," 'RAK',\n"," 'SPU',\n"," 'TLS',\n"," 'TNG',\n"," 'VCE',\n"," 'VRN',\n"," 'CLT',\n"," 'EWR',\n"," 'IAD',\n"," 'ORD',\n"," 'PHL',\n"," 'SFO',\n"," 'CMB',\n"," 'YYZ',\n"," 'CLT',\n"," 'IAD',\n"," 'ORD',\n"," 'PHL',\n"," 'RUN',\n"," 'AGP',\n"," 'BCN',\n"," 'BIO',\n"," 'GOT',\n"," 'VGO',\n"," 'VLC',\n"," 'AMS',\n"," 'HAN',\n"," 'SGN',\n"," 'VXE',\n"," 'MAD',\n"," 'SCQ',\n"," 'ARN',\n"," 'KEF',\n"," 'MCT',\n"," 'KEF',\n"," 'TGD',\n"," 'TIV',\n"," 'ALG',\n"," 'ORN']"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["routes = read_routes(airports_dict)\n","routes[\"CDG\"]"]},{"cell_type":"markdown","metadata":{},"source":["## 4. To do\n","\n","1.  Make sure you understand the first version of Pagerank above. Really, make sure, do not just transcribe it. \n","Make sure you see the connection with the matrix formulation in the course slides. \n","\n","2.  Now go to the 2nd version (disk friendly) of Pagerank. Make sure you understand\n","the key difference, and why it should be better with data in disk. \n","\n","3.  Implement it (the 2nd version) and try it on the following simple graph (graph used in course notes). Check that the pagerank values you obtain are those stated in the course notes from which the example comes from. Test the effect of changing the damping factor. If they don't come out right, first thing to check is that after each iteration\n","the sum of `P` is 1 (or close to 1 except for tiny rounding errors). If it's not, you are doing something wrong in the iteration step."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pprint"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["# a simple 4-node graph from the course slides\n","simple_graph = {\n","  1: [1, 3, 4],\n","  2: [1, 4],\n","  3: [2, 4],\n","  4: [2]\n","}\n","\n","def compute_pageranks(g, d):\n","    \"\"\" \n","    this function takes a dictionary g representing a graph and damping factor d, \n","    and outputs a list of (vertexname, pagerank) values for each vertex\n","    \"\"\"\n","    n = len(g)\n","    P = np.array([1/n]*n, dtype=np.float32)\n","    d = 0.85\n","    dist = np.inf\n","    \n","    while dist > 0.0001: \n","        Pnew = np.array([(1-d)/n]*n, dtype=np.float32) \n","        for i in g:\n","            for j in g[i]:\n","                Pnew[j-1] += d * P[i-1]/len(g[i])\n","        dist = np.linalg.norm(P-Pnew)\n","        P = Pnew\n","        \n","    return list(zip(g.keys(), P))"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[(1, 0.25301775), (2, 0.33837754), (3, 0.10917846), (4, 0.29942623)]\n"]}],"source":["compute_pageranks(simple_graph, 0.85)"]},{"cell_type":"markdown","metadata":{},"source":["4.  Now apply the pagerank algorithm to the graph of airport routes and look at the result. Are you surprised by the airports at the top (with most pagerank)?\n","\n","5. Experiment with different values of the damping factor, and how it affects the convergence rate (iterations and time)."]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["def compute_pageranks(g, d):\n","    \"\"\" \n","    This function takes a dictionary g representing a graph and damping factor d, \n","    and outputs a list of (vertexname, pagerank) values for each vertex\n","    \"\"\"\n","    n = len(airports_dict)\n","    vertex_names = list(airports_dict.keys())\n","    vertex_indices = {vertex_names[i]: i for i in range(n)}\n","\n","    P = np.array([1/n] * n, dtype=np.float32)\n","    dist = np.inf\n","    \n","    while dist > 0.0001: \n","        Pnew = np.array([(1-d)/n] * n, dtype=np.float32) \n","        for vertex in g:\n","            for neighbor in g[vertex]:\n","                Pnew[vertex_indices[neighbor]] += d * P[vertex_indices[vertex]] / len(g[vertex])\n","        dist = np.linalg.norm(P - Pnew)\n","        P = Pnew\n","        \n","    return list(zip(vertex_names, P)), sum(P)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["0.6347771681394079"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["a, b = compute_pageranks(routes, 0.85)\n","b"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":5}
