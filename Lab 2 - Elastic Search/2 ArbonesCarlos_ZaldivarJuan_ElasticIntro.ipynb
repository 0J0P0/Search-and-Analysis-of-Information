{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAI Lab Session 2: Intro to ElasticSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session you will learn:\n",
    "\n",
    "- a few basics of the `ElasticSearch` database\n",
    "- how to index a set of documents and how to ask simple queries about these documents\n",
    "- how to do this from `Python`\n",
    "- based on the previous, you will compute the boolean and tf-idf matrix for the toy corpus used in class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ElasticSearch\n",
    "\n",
    "[ElasticSearch](https://www.elastic.co/) is a _NoSQL/document_ database with the capability of indexing and searching text documents. As a rough analogue, we can use the following table for the equivalence between ElasticSearch and a more classical relational database:\n",
    "\n",
    "| Relational DB | ElasticSearch |\n",
    "|---|---|\n",
    "| Database | Index |\n",
    "| Table | Type |\n",
    "| Row / record | Document |\n",
    "| Column | Field |\n",
    "\n",
    "An index can be thought of as an optimized collection of documents and each document is a collection of fields, which are the key-value pairs that contain your data.\n",
    "\n",
    "`ElasticSearch` is a pretty big beast with many options. Luckily, there is much documentation, a few useful links are:\n",
    "\n",
    "- Here is the [full documentation](https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html)\n",
    "- Intros you may want to have a look at: \n",
    "    - https://medium.com/expedia-group-tech/getting-started-with-elastic-search-6af62d7df8dd\n",
    "    - http://joelabrahamsson.com/elasticsearch-101\n",
    "- You found another one that you liked? Let us know. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Running ElasticSearch\n",
    "\n",
    "First you will need to install `ElasticSearch` following instructions in their [documentation](https://www.elastic.co/guide/en/elasticsearch/reference/current/install-elasticsearch.html).\n",
    "\n",
    "This database runs as a web service in a machine and can be accessed using a REST web API; however we will interact with the database through its python libraries `elasticsearch-py` and `elasticsearch-dsl`, so you will need to install these as well.  You can run `ElasticSearch` by typing from the command-line prompt:\n",
    "\n",
    "```\n",
    "$ <path_to_elasticsearch_bin>/elasticsearch &\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a few seconds (and a lot of logging) the database will be up and running; you may need to hit return for the prompt to show up. To test whether `ElasticSearch` is working execute the code in the cell below. __The database needs to be running throughout the execution of this script, otherwise you will get a connection error.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b'{\\n  \"name\" : \"JPC2\",\\n  \"cluster_name\" : \"elasticsearch\",\\n  \"cluster_uuid'\n",
      " b'\" : \"H7sZwRSJTPC-bDvCrKVnLA\",\\n  \"version\" : {\\n    \"number\" : \"8.10.2\",\\n '\n",
      " b'   \"build_flavor\" : \"default\",\\n    \"build_type\" : \"zip\",\\n    \"build_hash'\n",
      " b'\" : \"6d20dd8ce62365be9b1aca96427de4622e970e9e\",\\n    \"build_date\" : \"2023'\n",
      " b'-09-19T08:16:24.564900370Z\",\\n    \"build_snapshot\" : false,\\n    \"lucene_v'\n",
      " b'ersion\" : \"9.7.0\",\\n    \"minimum_wire_compatibility_version\" : \"7.17.0\",\\n'\n",
      " b'    \"minimum_index_compatibility_version\" : \"7.0.0\"\\n  },\\n  \"tagline\" : \"'\n",
      " b'You Know, for Search\"\\n}\\n')\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "try:\n",
    "    resp = requests.get('http://localhost:9200/')\n",
    "    pprint(resp.content)\n",
    "    \n",
    "except Exception:\n",
    "    print('elasticsearch is not running')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `ElasticSearch` is working you will see an answer from the server; otherwise you will see a message indicating that it is not running. You can try also throwing the URL http://localhost:9200 to your browser; you should get a similar answer.\n",
    "\n",
    "**In version 8 they introduced enhanced security, which may give you trouble when executing the code here, to deal with this you can either install an earlier version (7 or older) or turn off security settings in their `config/elasticsearch.yml` config file (just set to _false_ everything concerning the security options).** Since we are using the database in offline, local mode this should not be a problem.\n",
    "\n",
    "Also, you should run this script locally in your machine, if you use Google Collab or similar this is not going to work because elasticsearch should be running on the machine where the script is being executed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Indexing and querying\n",
    "\n",
    "`ElasticSearch` is a database that allows storing documents (tables do not need a predefined schema as in relational databases). Text in these documents can be processed so the queries extend beyond exact matches allowing complex queries, fuzzy matching and ranking documents respect to the actual match. \n",
    "\n",
    "These kinds of databases are behind search engines like Google Search or Bing.\n",
    "\n",
    "There are different ways of operating with ElasticSearch. It is deployed esentially as a web service with a REST API, so it can be accessed basically from any language with a library for operating with HTTP servers.\n",
    "\n",
    "We are going to use two python libraries for programming on top of ElasticSearch: `elasticsearch` and `elasticsearch-dsl`. Both provide access to ElasticSearch functionalities hiding and making more programming-friendly the interactions, the second one is more convenient for configurating and searching. Make sure both python libraries are installed to proceed with this session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting elasticsearch\n",
      "  Obtaining dependency information for elasticsearch from https://files.pythonhosted.org/packages/61/81/d472e5679217fd61e6d052678f0c556978a43d79d8d6bf3b9c467dd15ba8/elasticsearch-8.10.0-py3-none-any.whl.metadata\n",
      "  Downloading elasticsearch-8.10.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting elastic-transport<9,>=8 (from elasticsearch)\n",
      "  Obtaining dependency information for elastic-transport<9,>=8 from https://files.pythonhosted.org/packages/7e/1c/13bb1826382a1275e9191e9ab5cac3c59247f49c4b4dd96b131ec123d9ff/elastic_transport-8.4.1-py3-none-any.whl.metadata\n",
      "  Downloading elastic_transport-8.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting urllib3<2,>=1.26.2 (from elastic-transport<9,>=8->elasticsearch)\n",
      "  Obtaining dependency information for urllib3<2,>=1.26.2 from https://files.pythonhosted.org/packages/c5/05/c214b32d21c0b465506f95c4f28ccbcba15022e000b043b72b3df7728471/urllib3-1.26.16-py2.py3-none-any.whl.metadata\n",
      "  Downloading urllib3-1.26.16-py2.py3-none-any.whl.metadata (48 kB)\n",
      "     -------------------------------------- 48.4/48.4 kB 615.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: certifi in c:\\users\\jpniz\\onedrive\\documentos\\upc\\q5\\.conda\\lib\\site-packages (from elastic-transport<9,>=8->elasticsearch) (2023.7.22)\n",
      "Using cached elasticsearch-8.10.0-py3-none-any.whl (414 kB)\n",
      "Using cached elastic_transport-8.4.1-py3-none-any.whl (59 kB)\n",
      "Downloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
      "   ---------------------------------------- 143.1/143.1 kB 4.3 MB/s eta 0:00:00\n",
      "Installing collected packages: urllib3, elastic-transport, elasticsearch\n",
      "Successfully installed elastic-transport-8.4.1 elasticsearch-8.10.0 urllib3-1.26.16\n",
      "Collecting elasticsearch-dsl\n",
      "  Obtaining dependency information for elasticsearch-dsl from https://files.pythonhosted.org/packages/92/4f/8966141ca545147b59d5869daa7a9bce34fb8f4a9ebd1d38cd23ba907a6f/elasticsearch_dsl-8.9.0-py3-none-any.whl.metadata\n",
      "  Downloading elasticsearch_dsl-8.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\jpniz\\appdata\\roaming\\python\\python311\\site-packages (from elasticsearch-dsl) (2.8.2)\n",
      "Requirement already satisfied: elasticsearch<9.0.0,>=8.0.0 in c:\\users\\jpniz\\appdata\\roaming\\python\\python311\\site-packages (from elasticsearch-dsl) (8.10.0)\n",
      "Requirement already satisfied: elastic-transport<9,>=8 in c:\\users\\jpniz\\appdata\\roaming\\python\\python311\\site-packages (from elasticsearch<9.0.0,>=8.0.0->elasticsearch-dsl) (8.4.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jpniz\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil->elasticsearch-dsl) (1.16.0)\n",
      "Requirement already satisfied: urllib3<2,>=1.26.2 in c:\\users\\jpniz\\appdata\\roaming\\python\\python311\\site-packages (from elastic-transport<9,>=8->elasticsearch<9.0.0,>=8.0.0->elasticsearch-dsl) (1.26.16)\n",
      "Requirement already satisfied: certifi in c:\\users\\jpniz\\onedrive\\documentos\\upc\\q5\\.conda\\lib\\site-packages (from elastic-transport<9,>=8->elasticsearch<9.0.0,>=8.0.0->elasticsearch-dsl) (2023.7.22)\n",
      "Using cached elasticsearch_dsl-8.9.0-py3-none-any.whl (62 kB)\n",
      "Installing collected packages: elasticsearch-dsl\n",
      "Successfully installed elasticsearch-dsl-8.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install elasticsearch --user\n",
    "!pip3 install elasticsearch-dsl --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only going to see the essential elements for developing the session but feel free to learn more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To interact with ElasticSearch with need a client object of type `Elasticsearch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jpniz\\AppData\\Local\\Temp\\ipykernel_25956\\2120730465.py:3: DeprecationWarning: The 'timeout' parameter is deprecated in favor of 'request_timeout'\n",
      "  client = Elasticsearch(\"http://localhost:9200\", timeout=1000)\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "client = Elasticsearch(\"http://localhost:9200\", timeout=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': 'JPC2', 'cluster_name': 'elasticsearch', 'cluster_uuid': 'H7sZwRSJTPC-bDvCrKVnLA', 'version': {'number': '8.10.2', 'build_flavor': 'default', 'build_type': 'zip', 'build_hash': '6d20dd8ce62365be9b1aca96427de4622e970e9e', 'build_date': '2023-09-19T08:16:24.564900370Z', 'build_snapshot': False, 'lucene_version': '9.7.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this client you have a connection for operating with Elastic search. Now we will create an index. There are index operations in each library, but the one in `elasticseach-dsl` is simpler to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch_dsl import Index\n",
    "\n",
    "index = Index('test', using=client)  # if it does not exist, it is created; if it does exist, then it connects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will need some text to index, for testing purposes we are going to use the python library `loremipsum`. We will need to install it first if it is not installed already, uncomment the code in next cell if you need to install the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lorem\n",
      "  Using cached lorem-0.1.1-py3-none-any.whl (5.0 kB)\n",
      "Installing collected packages: lorem\n",
      "Successfully installed lorem-0.1.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install lorem --user  # Restart the kernel if you are not able to import the library in the next cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create some random paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Velit quisquam sed ipsum tempora quaerat sit. Eius labore consectetur quaerat labore. Sit quisquam eius aliquam modi dolor. Voluptatem neque labore eius dolore. Etincidunt dolorem aliquam labore magnam labore.\n"
     ]
    }
   ],
   "source": [
    "import lorem\n",
    "\n",
    "texts = [lorem.paragraph() for _ in range(10)]\n",
    "print(len(texts))\n",
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can index the paragraphs in ElasticSearch using the `index` method. The document is passed as a python dictionary with the `document` parameter. The keys of the dictionary will be the fields of the document, in this case we well have only one (`text`) -- here, we use this tag but could use anything we wanted to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing new text: Velit quisquam sed ipsum tempora quaerat sit. Eius labore consectetur  ...\n",
      "Indexing new text: Velit amet tempora amet magnam voluptatem quisquam. Eius quisquam numq ...\n",
      "Indexing new text: Amet non tempora neque amet tempora sit quiquia. Ut velit modi velit p ...\n",
      "Indexing new text: Dolorem eius quiquia labore amet adipisci est. Dolor ut magnam eius mo ...\n",
      "Indexing new text: Dolorem eius voluptatem voluptatem adipisci. Quiquia porro aliquam est ...\n",
      "Indexing new text: Quiquia quaerat neque numquam porro aliquam. Voluptatem dolor ut modi  ...\n",
      "Indexing new text: Adipisci sed quiquia sit magnam etincidunt. Aliquam magnam dolor non d ...\n",
      "Indexing new text: Tempora magnam ipsum quiquia modi eius ut aliquam. Sed modi sit tempor ...\n",
      "Indexing new text: Eius dolore labore ut quisquam labore aliquam quiquia. Non sed volupta ...\n",
      "Indexing new text: Dolore quiquia porro quisquam. Numquam dolor est magnam magnam. Dolor  ...\n"
     ]
    }
   ],
   "source": [
    "for t in texts:\n",
    "    client.index(index='test', document={'text': t})\n",
    "    print(f'Indexing new text: {t[:70]} ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case we want to get all docs in the index, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['total', 'max_score', 'hits'])\n",
      "dict_keys(['_index', '_id', '_score', '_source'])\n",
      "Got 10 hits:\n",
      "{'text': 'Velit quisquam sed ipsum tempora quaerat sit. Eius labore '\n",
      "         'consectetur quaerat labore. Sit quisquam eius aliquam modi dolor. '\n",
      "         'Voluptatem neque labore eius dolore. Etincidunt dolorem aliquam '\n",
      "         'labore magnam labore.'}\n",
      "{'text': 'Velit amet tempora amet magnam voluptatem quisquam. Eius quisquam '\n",
      "         'numquam est. Consectetur sed labore velit. Aliquam modi adipisci '\n",
      "         'quaerat magnam dolor est dolore. Quiquia consectetur aliquam '\n",
      "         'consectetur etincidunt eius porro. Quaerat ipsum est eius.'}\n",
      "{'text': 'Amet non tempora neque amet tempora sit quiquia. Ut velit modi velit '\n",
      "         'porro dolore velit quaerat. Porro dolor eius numquam eius voluptatem '\n",
      "         'consectetur neque. Dolore est ut ut. Sed sed amet dolore labore '\n",
      "         'porro voluptatem sed. Eius modi numquam voluptatem quaerat adipisci '\n",
      "         'quisquam. Magnam consectetur tempora dolor aliquam aliquam magnam. '\n",
      "         'Eius dolor eius dolorem amet aliquam. Aliquam dolorem sit '\n",
      "         'consectetur etincidunt ut. Quiquia labore tempora ipsum ipsum '\n",
      "         'quisquam.'}\n",
      "{'text': 'Dolorem eius quiquia labore amet adipisci est. Dolor ut magnam eius '\n",
      "         'modi quisquam. Dolor numquam porro dolore ipsum. Aliquam ipsum sed '\n",
      "         'consectetur ut. Neque labore ut est ipsum dolore quisquam. Aliquam '\n",
      "         'est adipisci dolor sed dolore modi porro. Quaerat numquam labore '\n",
      "         'quiquia quiquia est modi eius.'}\n",
      "{'text': 'Dolorem eius voluptatem voluptatem adipisci. Quiquia porro aliquam '\n",
      "         'est quiquia labore amet sit. Adipisci neque ipsum quisquam adipisci. '\n",
      "         'Quiquia etincidunt velit velit dolor eius amet non. Quiquia '\n",
      "         'voluptatem etincidunt sed numquam numquam quaerat dolorem. Dolore '\n",
      "         'quiquia consectetur amet.'}\n",
      "{'text': 'Quiquia quaerat neque numquam porro aliquam. Voluptatem dolor ut '\n",
      "         'modi ipsum porro sed etincidunt. Magnam sed aliquam sed ut. Ipsum '\n",
      "         'consectetur porro quaerat. Magnam etincidunt quiquia non magnam '\n",
      "         'dolorem. Porro est sit dolorem dolore consectetur etincidunt.'}\n",
      "{'text': 'Adipisci sed quiquia sit magnam etincidunt. Aliquam magnam dolor non '\n",
      "         'dolore velit porro quaerat. Tempora etincidunt aliquam porro non '\n",
      "         'quisquam. Dolore dolore ipsum eius est eius etincidunt. Dolore '\n",
      "         'dolorem magnam voluptatem aliquam ut magnam. Ut aliquam quaerat '\n",
      "         'neque velit. Sit sed eius etincidunt adipisci dolorem consectetur '\n",
      "         'ipsum. Sit aliquam numquam velit porro.'}\n",
      "{'text': 'Tempora magnam ipsum quiquia modi eius ut aliquam. Sed modi sit '\n",
      "         'tempora. Sit porro est eius aliquam labore porro. Dolor dolorem eius '\n",
      "         'magnam tempora neque aliquam. Magnam sit sed voluptatem quaerat. '\n",
      "         'Amet etincidunt non porro velit etincidunt. Ut ut adipisci magnam. '\n",
      "         'Sit sit quisquam ipsum quiquia neque.'}\n",
      "{'text': 'Eius dolore labore ut quisquam labore aliquam quiquia. Non sed '\n",
      "         'voluptatem voluptatem consectetur etincidunt porro. Quiquia tempora '\n",
      "         'quisquam non dolorem. Quiquia sit quisquam dolore dolor porro. '\n",
      "         'Quisquam porro dolor sed quiquia modi ut modi. Aliquam numquam '\n",
      "         'dolore eius aliquam. Consectetur tempora neque amet sit amet. '\n",
      "         'Numquam ut est labore dolore.'}\n",
      "{'text': 'Dolore quiquia porro quisquam. Numquam dolor est magnam magnam. '\n",
      "         'Dolor voluptatem aliquam eius dolore quiquia. Dolor dolor amet '\n",
      "         'neque. Eius amet dolore consectetur consectetur aliquam. Dolore amet '\n",
      "         'porro tempora consectetur eius. Ipsum numquam consectetur etincidunt '\n",
      "         'magnam neque etincidunt quiquia. Ipsum quisquam labore adipisci '\n",
      "         'numquam voluptatem consectetur.'}\n"
     ]
    }
   ],
   "source": [
    "# get all docs in index 'test'\n",
    "resp = client.search(index=\"test\", query={\"match_all\": {}})\n",
    "\n",
    "# print them\n",
    "# print(f\"{resp['hits'].keys()}\")\n",
    "# print(f\"{resp['hits']['total'].keys()}\")\n",
    "# print(f\"{resp['hits']['hits'][0].keys()}\")\n",
    "\n",
    "print(f\"Got {resp['hits']['total']['value']} hits:\")\n",
    "for hit in resp['hits']['hits']:\n",
    "    pprint(hit[\"_source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also search for documents that contain a given keyword:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 matches.\n",
      "\n",
      "ID: 6GY1mIoB1aJZhB_GIOs0\n",
      "Text: Velit ut numquam dolore sit dolorem quisquam. Sit consectetur neque velit est consectetur non voluptatem. Ipsum dolorem dolorem voluptatem amet velit numquam quaerat. Sed labore labore non. Ut tempora etincidunt sed ipsum non modi consectetur.\n",
      "\n",
      "ID: 5GY1mIoB1aJZhB_GH-uq\n",
      "Text: Consectetur etincidunt non magnam consectetur voluptatem eius. Quiquia magnam sit dolore est quisquam. Sed voluptatem ipsum ut sed porro. Sed ut velit dolore quaerat. Labore porro non consectetur. Quaerat porro labore non quisquam amet sit numquam. Adipisci labore amet magnam velit neque labore adipisci.\n",
      "\n",
      "ID: 52Y1mIoB1aJZhB_GIOsS\n",
      "Text: Numquam etincidunt magnam sed aliquam amet. Dolorem non labore quaerat voluptatem. Est eius non dolorem consectetur voluptatem sed sit. Modi quiquia ipsum neque labore velit ipsum etincidunt. Dolor ut etincidunt magnam. Sit sed ipsum est modi. Consectetur ut eius ut. Dolorem sit voluptatem neque.\n",
      "\n",
      "ID: 6mY1mIoB1aJZhB_GIOt2\n",
      "Text: Consectetur ut dolorem sed dolor labore velit. Ipsum velit ut aliquam. Quisquam quisquam eius dolore. Est adipisci voluptatem neque non dolore sed. Sed ut sit voluptatem consectetur quaerat dolor non. Quisquam velit amet ut aliquam dolore consectetur. Labore quisquam sit dolorem. Labore quiquia ipsum velit. Labore magnam amet quiquia amet quiquia sit eius.\n",
      "\n",
      "ID: 6WY1mIoB1aJZhB_GIOtU\n",
      "Text: Numquam dolorem dolorem eius tempora. Sed non quisquam etincidunt sed numquam. Ipsum sit quisquam etincidunt numquam quiquia labore neque. Est dolore labore ipsum. Quisquam amet consectetur ut tempora sit.\n",
      "\n",
      "ID: 5WY1mIoB1aJZhB_GH-vJ\n",
      "Text: Ipsum consectetur velit sed ipsum numquam modi. Est labore non ipsum est. Sed dolorem porro neque ut ut adipisci. Modi consectetur amet etincidunt. Quiquia tempora consectetur voluptatem sed porro sed labore.\n",
      "\n",
      "ID: 5mY1mIoB1aJZhB_GH-vx\n",
      "Text: Velit sit sit est voluptatem est adipisci. Quiquia quisquam magnam sed sed adipisci. Consectetur velit neque dolorem. Dolorem etincidunt dolor labore dolorem eius voluptatem. Est sit non sit est quaerat ipsum dolorem. Aliquam porro etincidunt eius. Labore sed amet dolorem. Numquam tempora quiquia eius. Ut consectetur magnam ipsum numquam aliquam dolor velit.\n",
      "\n",
      "ID: 7GY1mIoB1aJZhB_GIOus\n",
      "Text: Ut tempora quisquam ipsum consectetur numquam dolorem. Etincidunt numquam quiquia aliquam dolorem. Amet adipisci voluptatem magnam. Consectetur dolore quisquam magnam etincidunt consectetur. Consectetur porro voluptatem aliquam dolor porro etincidunt amet. Porro aliquam est consectetur eius ipsum ut etincidunt. Quisquam tempora non quaerat neque etincidunt. Adipisci dolor magnam quaerat eius aliquam. Magnam velit amet est amet.\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch_dsl import Search\n",
    "\n",
    "# the following search query specifies the field where we want to search\n",
    "s_obj = Search(using=client, index='test')\n",
    "sq = s_obj.query('match', text='non')\n",
    "resp = sq.execute()\n",
    "\n",
    "print(f'Found {len(resp)} matches.')\n",
    "\n",
    "for hit in resp:\n",
    "    print(f'\\nID: {hit.meta.id}\\nText: {hit.text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Counting words and docs\n",
    "\n",
    "`Elastic search` helps us to obtain the counts of words in each document. For example, the following code obtains the counts of words of a whole index by adding the counts of words obtained from each document through the functionality of `termvectors`. This function also allows us to get _document counts_ for computing tf-idf weights, by setting the `term_statistics` option to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch.helpers import scan\n",
    "from collections import Counter\n",
    "\n",
    "# Search for all the documents and query the list of (word, frequency) of each one\n",
    "# Totals are accumulated using a Counter for term frequencies, but not for document freqs.\n",
    "word_counts = Counter()\n",
    "doc_counts = Counter()\n",
    "sc = scan(client, index='test', query={\"query\" : {\"match_all\": {}}})\n",
    "for s in sc:\n",
    "    tv = client.termvectors(index='test', id=s['_id'], fields=['text'], term_statistics=True, positions=False)\n",
    "    if 'text' in tv['term_vectors']:   # just in case some document has no field named 'text'\n",
    "        for t in tv['term_vectors']['text']['terms']:\n",
    "            word = t\n",
    "            count = tv['term_vectors']['text']['terms'][t]['term_freq']\n",
    "            df = tv['term_vectors']['text']['terms'][t]['doc_freq']\n",
    "            #pprint(tv['term_vectors']['text']['terms'][t])\n",
    "            word_counts.update({word: count})\n",
    "            doc_counts[word] = df      # the counts are not added to avoid overcounting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('consectetur', 28),\n",
       " ('sed', 27),\n",
       " ('ipsum', 23),\n",
       " ('labore', 23),\n",
       " ('eius', 22),\n",
       " ('est', 21),\n",
       " ('quisquam', 21),\n",
       " ('amet', 20),\n",
       " ('ut', 20),\n",
       " ('sit', 19),\n",
       " ('numquam', 18),\n",
       " ('dolorem', 18),\n",
       " ('etincidunt', 17),\n",
       " ('magnam', 16),\n",
       " ('voluptatem', 16),\n",
       " ('dolore', 15),\n",
       " ('velit', 15),\n",
       " ('aliquam', 14),\n",
       " ('non', 14),\n",
       " ('adipisci', 13),\n",
       " ('quiquia', 13),\n",
       " ('modi', 11),\n",
       " ('neque', 11),\n",
       " ('porro', 11),\n",
       " ('dolor', 10),\n",
       " ('quaerat', 9),\n",
       " ('tempora', 8)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show word frequencies\n",
    "word_counts.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('amet', 10),\n",
       " ('consectetur', 10),\n",
       " ('est', 10),\n",
       " ('ipsum', 10),\n",
       " ('ut', 10),\n",
       " ('etincidunt', 9),\n",
       " ('labore', 9),\n",
       " ('neque', 9),\n",
       " ('numquam', 9),\n",
       " ('quiquia', 9),\n",
       " ('sed', 9),\n",
       " ('voluptatem', 9),\n",
       " ('eius', 8),\n",
       " ('quisquam', 8),\n",
       " ('non', 8),\n",
       " ('adipisci', 7),\n",
       " ('dolore', 7),\n",
       " ('magnam', 7),\n",
       " ('quaerat', 7),\n",
       " ('sit', 7),\n",
       " ('velit', 7),\n",
       " ('dolorem', 7),\n",
       " ('aliquam', 6),\n",
       " ('dolor', 6),\n",
       " ('porro', 6),\n",
       " ('tempora', 6),\n",
       " ('modi', 5)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show doc freq\n",
    "doc_counts.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Proposed simple exercise\n",
    "\n",
    "To get more familiar with elasticsearch, we propose that you _generate the Boolean and tf-idf matrices_ for the toy example that we used in class. You will find 7 text documents that contain the toy documents with the materials for this session in the racó. The steps to follow are:\n",
    "\n",
    "- create an empty index\n",
    "- open each text document in the `toy-docs` folder provided, read its contents and add it to the index as a new document; your index should contain 7 documents after this\n",
    "- use the `termvectors` function to obtain term and doc counts, generate Boolean and tf-idf matrices based on these counts\n",
    "- double check that your results coincide with the numbers in theory slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cleanup\n",
    "\n",
    "Finally, we remove the test index.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {
    "height": "135px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
