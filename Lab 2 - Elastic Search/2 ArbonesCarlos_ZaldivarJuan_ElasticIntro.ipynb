{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAI Lab Session 2: Intro to ElasticSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session you will learn:\n",
    "\n",
    "- a few basics of the `ElasticSearch` database\n",
    "- how to index a set of documents and how to ask simple queries about these documents\n",
    "- how to do this from `Python`\n",
    "- based on the previous, you will compute the boolean and tf-idf matrix for the toy corpus used in class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ElasticSearch\n",
    "\n",
    "[ElasticSearch](https://www.elastic.co/) is a _NoSQL/document_ database with the capability of indexing and searching text documents. As a rough analogue, we can use the following table for the equivalence between ElasticSearch and a more classical relational database:\n",
    "\n",
    "| Relational DB | ElasticSearch |\n",
    "|---|---|\n",
    "| Database | Index |\n",
    "| Table | Type |\n",
    "| Row / record | Document |\n",
    "| Column | Field |\n",
    "\n",
    "An index can be thought of as an optimized collection of documents and each document is a collection of fields, which are the key-value pairs that contain your data.\n",
    "\n",
    "`ElasticSearch` is a pretty big beast with many options. Luckily, there is much documentation, a few useful links are:\n",
    "\n",
    "- Here is the [full documentation](https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html)\n",
    "- Intros you may want to have a look at: \n",
    "    - https://medium.com/expedia-group-tech/getting-started-with-elastic-search-6af62d7df8dd\n",
    "    - http://joelabrahamsson.com/elasticsearch-101\n",
    "- You found another one that you liked? Let us know. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Running ElasticSearch\n",
    "\n",
    "First you will need to install `ElasticSearch` following instructions in their [documentation](https://www.elastic.co/guide/en/elasticsearch/reference/current/install-elasticsearch.html).\n",
    "\n",
    "This database runs as a web service in a machine and can be accessed using a REST web API; however we will interact with the database through its python libraries `elasticsearch-py` and `elasticsearch-dsl`, so you will need to install these as well.  You can run `ElasticSearch` by typing from the command-line prompt:\n",
    "\n",
    "```\n",
    "$ <path_to_elasticsearch_bin>/elasticsearch &\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a few seconds (and a lot of logging) the database will be up and running; you may need to hit return for the prompt to show up. To test whether `ElasticSearch` is working execute the code in the cell below. __The database needs to be running throughout the execution of this script, otherwise you will get a connection error.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b'{\\n  \"name\" : \"DESKTOP-QNOM0EQ\",\\n  \"cluster_name\" : \"elasticsearch\",\\n  \"c'\n",
      " b'luster_uuid\" : \"eig_fG5ySRWEscM_Y6LUcQ\",\\n  \"version\" : {\\n    \"number\" : '\n",
      " b'\"8.10.2\",\\n    \"build_flavor\" : \"default\",\\n    \"build_type\" : \"zip\",\\n    '\n",
      " b'\"build_hash\" : \"6d20dd8ce62365be9b1aca96427de4622e970e9e\",\\n    \"build_da'\n",
      " b'te\" : \"2023-09-19T08:16:24.564900370Z\",\\n    \"build_snapshot\" : false,\\n  '\n",
      " b'  \"lucene_version\" : \"9.7.0\",\\n    \"minimum_wire_compatibility_version\" :'\n",
      " b' \"7.17.0\",\\n    \"minimum_index_compatibility_version\" : \"7.0.0\"\\n  },\\n  \"t'\n",
      " b'agline\" : \"You Know, for Search\"\\n}\\n')\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "try:\n",
    "    resp = requests.get('http://localhost:9200/')\n",
    "    pprint(resp.content)\n",
    "    \n",
    "except Exception:\n",
    "    print('elasticsearch is not running')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `ElasticSearch` is working you will see an answer from the server; otherwise you will see a message indicating that it is not running. You can try also throwing the URL http://localhost:9200 to your browser; you should get a similar answer.\n",
    "\n",
    "**In version 8 they introduced enhanced security, which may give you trouble when executing the code here, to deal with this you can either install an earlier version (7 or older) or turn off security settings in their `config/elasticsearch.yml` config file (just set to _false_ everything concerning the security options).** Since we are using the database in offline, local mode this should not be a problem.\n",
    "\n",
    "Also, you should run this script locally in your machine, if you use Google Collab or similar this is not going to work because elasticsearch should be running on the machine where the script is being executed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Indexing and querying\n",
    "\n",
    "`ElasticSearch` is a database that allows storing documents (tables do not need a predefined schema as in relational databases). Text in these documents can be processed so the queries extend beyond exact matches allowing complex queries, fuzzy matching and ranking documents respect to the actual match. \n",
    "\n",
    "These kinds of databases are behind search engines like Google Search or Bing.\n",
    "\n",
    "There are different ways of operating with ElasticSearch. It is deployed esentially as a web service with a REST API, so it can be accessed basically from any language with a library for operating with HTTP servers.\n",
    "\n",
    "We are going to use two python libraries for programming on top of ElasticSearch: `elasticsearch` and `elasticsearch-dsl`. Both provide access to ElasticSearch functionalities hiding and making more programming-friendly the interactions, the second one is more convenient for configurating and searching. Make sure both python libraries are installed to proceed with this session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only going to see the essential elements for developing the session but feel free to learn more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To interact with ElasticSearch with need a client object of type `Elasticsearch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carlos Arbonés\\AppData\\Local\\Temp\\ipykernel_11192\\2120730465.py:3: DeprecationWarning: The 'timeout' parameter is deprecated in favor of 'request_timeout'\n",
      "  client = Elasticsearch(\"http://localhost:9200\", timeout=1000)\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "client = Elasticsearch(\"http://localhost:9200\", timeout=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this client you have a connection for operating with Elastic search. Now we will create an index. There are index operations in each library, but the one in `elasticseach-dsl` is simpler to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch_dsl import Index\n",
    "\n",
    "index = Index('test', using=client)  # if it does not exist, it is created; if it does exist, then it connects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will need some text to index, for testing purposes we are going to use the python library `loremipsum`. We will need to install it first if it is not installed already, uncomment the code in next cell if you need to install the library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create some random paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "('Numquam est etincidunt ut labore velit. Quaerat non dolore tempora porro '\n",
      " 'consectetur. Consectetur quaerat sit quiquia labore quaerat. Dolorem '\n",
      " 'adipisci quisquam consectetur tempora voluptatem modi velit. Neque aliquam '\n",
      " 'quaerat amet dolore sit dolor dolore. Dolor voluptatem etincidunt velit '\n",
      " 'tempora magnam labore. Velit labore non dolore etincidunt quaerat est.')\n"
     ]
    }
   ],
   "source": [
    "import lorem\n",
    "\n",
    "texts = [lorem.paragraph() for _ in range(10)]\n",
    "print(len(texts))\n",
    "pprint(texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can index the paragraphs in ElasticSearch using the `index` method. The document is passed as a python dictionary with the `document` parameter. The keys of the dictionary will be the fields of the document, in this case we well have only one (`text`) -- here, we use this tag but could use anything we wanted to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing new text: Numquam est etincidunt ut labore velit. Quaerat non dolore tempora por ...\n",
      "Indexing new text: Velit magnam neque porro. Voluptatem quiquia ipsum amet. Quaerat conse ...\n",
      "Indexing new text: Est quaerat magnam quiquia. Consectetur quiquia quiquia numquam velit  ...\n",
      "Indexing new text: Neque ipsum tempora modi dolore. Consectetur porro non neque voluptate ...\n",
      "Indexing new text: Quaerat magnam quisquam porro neque. Neque neque magnam quaerat. Sit n ...\n",
      "Indexing new text: Aliquam neque est ipsum. Ut consectetur ut est tempora ipsum modi dolo ...\n",
      "Indexing new text: Modi velit eius labore eius. Magnam est ut dolorem labore sed. Etincid ...\n",
      "Indexing new text: Tempora tempora labore non numquam numquam. Est quiquia quisquam magna ...\n",
      "Indexing new text: Non adipisci quaerat numquam numquam numquam quaerat. Consectetur dolo ...\n",
      "Indexing new text: Ipsum magnam labore modi numquam. Modi aliquam ut quiquia adipisci vol ...\n"
     ]
    }
   ],
   "source": [
    "for t in texts:\n",
    "    client.index(index='test', document={'text': t})\n",
    "    print(f'Indexing new text: {t[:70]} ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case we want to get all docs in the index, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 10 hits:\n",
      "{'text': 'Magnam etincidunt ipsum voluptatem ipsum quaerat dolorem. Numquam '\n",
      "         'dolor eius aliquam porro non. Dolore tempora numquam velit amet est '\n",
      "         'dolor dolore. Quiquia adipisci aliquam ut non ut. Numquam neque '\n",
      "         'etincidunt etincidunt adipisci. Dolore tempora ipsum quisquam amet '\n",
      "         'neque. Magnam numquam amet voluptatem. Consectetur quiquia non '\n",
      "         'consectetur ut velit modi. Dolorem ut ipsum dolor.'}\n",
      "{'text': 'Ut dolore sed etincidunt. Magnam adipisci adipisci magnam dolor '\n",
      "         'porro. Etincidunt consectetur porro quaerat sit neque dolore '\n",
      "         'consectetur. Sed neque consectetur amet ut. Sit dolore modi labore '\n",
      "         'sed.'}\n",
      "{'text': 'Quaerat non eius adipisci labore. Labore ipsum modi numquam ut. '\n",
      "         'Adipisci amet ipsum tempora dolorem porro. Ut amet voluptatem magnam '\n",
      "         'consectetur non. Sed consectetur adipisci eius ipsum dolore est. '\n",
      "         'Eius dolore ipsum dolor ut quaerat dolore. Quisquam ipsum labore sed '\n",
      "         'voluptatem eius dolore eius.'}\n",
      "{'text': 'Amet numquam numquam consectetur amet. Etincidunt quaerat ut porro '\n",
      "         'voluptatem eius. Quisquam amet aliquam non quaerat est. Neque '\n",
      "         'quisquam sit aliquam. Quaerat dolore velit sed. Numquam sed '\n",
      "         'voluptatem quiquia eius. Eius sed ipsum tempora labore ipsum tempora '\n",
      "         'tempora. Velit tempora magnam aliquam sit quiquia ipsum.'}\n",
      "{'text': 'Amet dolorem amet tempora adipisci. Sed dolore dolore voluptatem '\n",
      "         'modi labore. Ut quisquam dolor quisquam neque. Est tempora sit ut '\n",
      "         'non est etincidunt dolor. Porro est sed consectetur. Consectetur '\n",
      "         'dolor ipsum eius velit. Quaerat quiquia non consectetur labore '\n",
      "         'labore. Ipsum etincidunt quisquam ut ut adipisci sit labore. Dolorem '\n",
      "         'sit amet ipsum adipisci velit.'}\n",
      "{'text': 'Adipisci magnam dolor neque porro adipisci voluptatem. Quaerat sed '\n",
      "         'ut quaerat. Sit quisquam numquam quisquam consectetur. Sit numquam '\n",
      "         'consectetur quiquia tempora. Dolorem eius labore labore aliquam '\n",
      "         'aliquam adipisci ut. Aliquam velit velit etincidunt porro neque '\n",
      "         'dolorem. Magnam aliquam adipisci quaerat dolor.'}\n",
      "{'text': 'Amet quisquam numquam amet neque eius ut labore. Aliquam sed tempora '\n",
      "         'amet quiquia magnam. Eius neque sed modi dolor. Quisquam porro sed '\n",
      "         'quiquia. Ut modi est sit aliquam neque eius dolorem. Quiquia eius '\n",
      "         'sed consectetur etincidunt etincidunt quisquam dolore. Non porro '\n",
      "         'adipisci etincidunt ut dolore magnam adipisci. Consectetur sed non '\n",
      "         'eius dolor adipisci amet velit. Numquam ipsum velit etincidunt eius. '\n",
      "         'Modi consectetur quisquam quaerat velit.'}\n",
      "{'text': 'Modi ut magnam porro adipisci non amet velit. Dolor quaerat aliquam '\n",
      "         'magnam. Quisquam magnam velit amet quaerat est eius quiquia. Aliquam '\n",
      "         'adipisci sit etincidunt. Quisquam tempora labore eius.'}\n",
      "{'text': 'Adipisci voluptatem etincidunt quaerat quaerat. Dolore sit numquam '\n",
      "         'est quiquia velit dolorem tempora. Ipsum ipsum dolorem numquam '\n",
      "         'magnam dolorem. Sed dolorem ut ut tempora est. Aliquam amet tempora '\n",
      "         'consectetur. Magnam sit dolor eius tempora non neque. Quaerat '\n",
      "         'dolorem aliquam numquam. Quiquia magnam numquam modi dolorem '\n",
      "         'aliquam. Etincidunt labore sit adipisci adipisci tempora dolor '\n",
      "         'neque. Dolor dolore quaerat tempora neque etincidunt ut dolore.'}\n",
      "{'text': 'Est ut etincidunt quaerat. Dolor est magnam dolor neque dolorem. '\n",
      "         'Ipsum ipsum tempora adipisci eius aliquam consectetur quaerat. '\n",
      "         'Dolore sit est tempora non voluptatem dolorem. Eius consectetur '\n",
      "         'consectetur ipsum dolore neque magnam. Dolor labore porro numquam '\n",
      "         'adipisci magnam labore. Magnam neque aliquam amet. Quaerat porro '\n",
      "         'dolore sed. Sit velit voluptatem magnam.'}\n"
     ]
    }
   ],
   "source": [
    "# get all docs in index 'test'\n",
    "resp = client.search(index=\"test\", query={\"match_all\": {}})\n",
    "\n",
    "# print them\n",
    "print(f\"Got {resp['hits']['total']['value']} hits:\")\n",
    "for hit in resp['hits']['hits']:\n",
    "    pprint(hit[\"_source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also search for documents that contain a given keyword:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 matches.\n",
      "\n",
      "ID: K2-W74oBgkzt8pv6sy-0\n",
      "Text: Magnam etincidunt ipsum voluptatem ipsum quaerat dolorem. Numquam dolor eius aliquam porro non. Dolore tempora numquam velit amet est dolor dolore. Quiquia adipisci aliquam ut non ut. Numquam neque etincidunt etincidunt adipisci. Dolore tempora ipsum quisquam amet neque. Magnam numquam amet voluptatem. Consectetur quiquia non consectetur ut velit modi. Dolorem ut ipsum dolor.\n",
      "\n",
      "ID: LW-W74oBgkzt8pv6tC-g\n",
      "Text: Quaerat non eius adipisci labore. Labore ipsum modi numquam ut. Adipisci amet ipsum tempora dolorem porro. Ut amet voluptatem magnam consectetur non. Sed consectetur adipisci eius ipsum dolore est. Eius dolore ipsum dolor ut quaerat dolore. Quisquam ipsum labore sed voluptatem eius dolore eius.\n",
      "\n",
      "ID: L2-W74oBgkzt8pv6tC-4\n",
      "Text: Amet dolorem amet tempora adipisci. Sed dolore dolore voluptatem modi labore. Ut quisquam dolor quisquam neque. Est tempora sit ut non est etincidunt dolor. Porro est sed consectetur. Consectetur dolor ipsum eius velit. Quaerat quiquia non consectetur labore labore. Ipsum etincidunt quisquam ut ut adipisci sit labore. Dolorem sit amet ipsum adipisci velit.\n",
      "\n",
      "ID: MW-W74oBgkzt8pv6tC_M\n",
      "Text: Amet quisquam numquam amet neque eius ut labore. Aliquam sed tempora amet quiquia magnam. Eius neque sed modi dolor. Quisquam porro sed quiquia. Ut modi est sit aliquam neque eius dolorem. Quiquia eius sed consectetur etincidunt etincidunt quisquam dolore. Non porro adipisci etincidunt ut dolore magnam adipisci. Consectetur sed non eius dolor adipisci amet velit. Numquam ipsum velit etincidunt eius. Modi consectetur quisquam quaerat velit.\n",
      "\n",
      "ID: Mm-W74oBgkzt8pv6tC_T\n",
      "Text: Modi ut magnam porro adipisci non amet velit. Dolor quaerat aliquam magnam. Quisquam magnam velit amet quaerat est eius quiquia. Aliquam adipisci sit etincidunt. Quisquam tempora labore eius.\n",
      "\n",
      "ID: Lm-W74oBgkzt8pv6tC-j\n",
      "Text: Amet numquam numquam consectetur amet. Etincidunt quaerat ut porro voluptatem eius. Quisquam amet aliquam non quaerat est. Neque quisquam sit aliquam. Quaerat dolore velit sed. Numquam sed voluptatem quiquia eius. Eius sed ipsum tempora labore ipsum tempora tempora. Velit tempora magnam aliquam sit quiquia ipsum.\n",
      "\n",
      "ID: NG-W74oBgkzt8pv6tC_p\n",
      "Text: Est ut etincidunt quaerat. Dolor est magnam dolor neque dolorem. Ipsum ipsum tempora adipisci eius aliquam consectetur quaerat. Dolore sit est tempora non voluptatem dolorem. Eius consectetur consectetur ipsum dolore neque magnam. Dolor labore porro numquam adipisci magnam labore. Magnam neque aliquam amet. Quaerat porro dolore sed. Sit velit voluptatem magnam.\n",
      "\n",
      "ID: M2-W74oBgkzt8pv6tC_h\n",
      "Text: Adipisci voluptatem etincidunt quaerat quaerat. Dolore sit numquam est quiquia velit dolorem tempora. Ipsum ipsum dolorem numquam magnam dolorem. Sed dolorem ut ut tempora est. Aliquam amet tempora consectetur. Magnam sit dolor eius tempora non neque. Quaerat dolorem aliquam numquam. Quiquia magnam numquam modi dolorem aliquam. Etincidunt labore sit adipisci adipisci tempora dolor neque. Dolor dolore quaerat tempora neque etincidunt ut dolore.\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch_dsl import Search\n",
    "\n",
    "# the following search query specifies the field where we want to search\n",
    "s_obj = Search(using=client, index='test')\n",
    "sq = s_obj.query('match', text='non')\n",
    "resp = sq.execute()\n",
    "\n",
    "print(f'Found {len(resp)} matches.')\n",
    "\n",
    "for hit in resp:\n",
    "    print(f'\\nID: {hit.meta.id}\\nText: {hit.text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Counting words and docs\n",
    "\n",
    "`Elastic search` helps us to obtain the counts of words in each document. For example, the following code obtains the counts of words of a whole index by adding the counts of words obtained from each document through the functionality of `termvectors`. This function also allows us to get _document counts_ for computing tf-idf weights, by setting the `term_statistics` option to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch.helpers import scan\n",
    "from collections import Counter\n",
    "\n",
    "# Search for all the documents and query the list of (word, frequency) of each one\n",
    "# Totals are accumulated using a Counter for term frequencies, but not for document freqs.\n",
    "word_counts = Counter()\n",
    "doc_counts = Counter()\n",
    "sc = scan(client, index='test', query={\"query\" : {\"match_all\": {}}})\n",
    "for s in sc:\n",
    "    tv = client.termvectors(index='test', id=s['_id'], fields=['text'], term_statistics=True, positions=False)\n",
    "    if 'text' in tv['term_vectors']:   # just in case some document has no field named 'text'\n",
    "        for t in tv['term_vectors']['text']['terms']:\n",
    "            word = t\n",
    "            count = tv['term_vectors']['text']['terms'][t]['term_freq']\n",
    "            df = tv['term_vectors']['text']['terms'][t]['doc_freq']\n",
    "            #pprint(tv['term_vectors']['text']['terms'][t])\n",
    "            word_counts.update({word: count})\n",
    "            doc_counts[word] = df      # the counts are not added to avoid overcounting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('adipisci', 24),\n",
       " ('ut', 24),\n",
       " ('eius', 22),\n",
       " ('dolore', 21),\n",
       " ('ipsum', 21),\n",
       " ('magnam', 21),\n",
       " ('quaerat', 21),\n",
       " ('amet', 20),\n",
       " ('consectetur', 20),\n",
       " ('tempora', 20),\n",
       " ('dolor', 19),\n",
       " ('aliquam', 18),\n",
       " ('etincidunt', 18),\n",
       " ('sed', 18),\n",
       " ('neque', 17),\n",
       " ('numquam', 17),\n",
       " ('dolorem', 16),\n",
       " ('labore', 16),\n",
       " ('sit', 16),\n",
       " ('quisquam', 15),\n",
       " ('velit', 15),\n",
       " ('est', 13),\n",
       " ('non', 13),\n",
       " ('porro', 13),\n",
       " ('quiquia', 12),\n",
       " ('voluptatem', 11),\n",
       " ('modi', 9)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show word frequencies\n",
    "word_counts.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('consectetur', 19),\n",
       " ('magnam', 19),\n",
       " ('quaerat', 19),\n",
       " ('tempora', 19),\n",
       " ('adipisci', 18),\n",
       " ('amet', 18),\n",
       " ('neque', 18),\n",
       " ('ut', 18),\n",
       " ('labore', 18),\n",
       " ('modi', 17),\n",
       " ('non', 17),\n",
       " ('porro', 17),\n",
       " ('quisquam', 17),\n",
       " ('velit', 17),\n",
       " ('voluptatem', 17),\n",
       " ('dolor', 16),\n",
       " ('dolore', 16),\n",
       " ('eius', 16),\n",
       " ('est', 16),\n",
       " ('numquam', 16),\n",
       " ('sed', 16),\n",
       " ('dolorem', 15),\n",
       " ('sit', 15),\n",
       " ('aliquam', 14),\n",
       " ('etincidunt', 14),\n",
       " ('ipsum', 14),\n",
       " ('quiquia', 13)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show doc freq\n",
    "doc_counts.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Proposed simple exercise\n",
    "\n",
    "To get more familiar with elasticsearch, we propose that you _generate the Boolean and tf-idf matrices_ for the toy example that we used in class. You will find 7 text documents that contain the toy documents with the materials for this session in the racó. The steps to follow are:\n",
    "\n",
    "- create an empty index\n",
    "- open each text document in the `toy-docs` folder provided, read its contents and add it to the index as a new document; your index should contain 7 documents after this\n",
    "- use the `termvectors` function to obtain term and doc counts, generate Boolean and tf-idf matrices based on these counts\n",
    "- double check that your results coincide with the numbers in theory slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch_dsl import Index\n",
    "\n",
    "index = Index('exercise', using=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 8):\n",
    "    with open('toy-docs/' + f'd{i}.txt', 'r') as f:\n",
    "        text = f.read()\n",
    "        client.index(index='exercise', document={'text': text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 7 hits\n"
     ]
    }
   ],
   "source": [
    "resp = client.search(index=\"exercise\", query={\"match_all\": {}})\n",
    "print(f\"Got {resp['hits']['total']['value']} hits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cleanup\n",
    "\n",
    "Finally, we remove the test index.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {
    "height": "135px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
