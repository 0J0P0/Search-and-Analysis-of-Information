{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAI Lab Session 2: Intro to ElasticSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session you will learn:\n",
    "\n",
    "- a few basics of the `ElasticSearch` database\n",
    "- how to index a set of documents and how to ask simple queries about these documents\n",
    "- how to do this from `Python`\n",
    "- based on the previous, you will compute the boolean and tf-idf matrix for the toy corpus used in class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ElasticSearch\n",
    "\n",
    "[ElasticSearch](https://www.elastic.co/) is a _NoSQL/document_ database with the capability of indexing and searching text documents. As a rough analogue, we can use the following table for the equivalence between ElasticSearch and a more classical relational database:\n",
    "\n",
    "| Relational DB | ElasticSearch |\n",
    "|---|---|\n",
    "| Database | Index |\n",
    "| Table | Type |\n",
    "| Row / record | Document |\n",
    "| Column | Field |\n",
    "\n",
    "An index can be thought of as an optimized collection of documents and each document is a collection of fields, which are the key-value pairs that contain your data.\n",
    "\n",
    "`ElasticSearch` is a pretty big beast with many options. Luckily, there is much documentation, a few useful links are:\n",
    "\n",
    "- Here is the [full documentation](https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html)\n",
    "- Intros you may want to have a look at: \n",
    "    - https://medium.com/expedia-group-tech/getting-started-with-elastic-search-6af62d7df8dd\n",
    "    - http://joelabrahamsson.com/elasticsearch-101\n",
    "- You found another one that you liked? Let us know. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Running ElasticSearch\n",
    "\n",
    "First you will need to install `ElasticSearch` following instructions in their [documentation](https://www.elastic.co/guide/en/elasticsearch/reference/current/install-elasticsearch.html).\n",
    "\n",
    "This database runs as a web service in a machine and can be accessed using a REST web API; however we will interact with the database through its python libraries `elasticsearch-py` and `elasticsearch-dsl`, so you will need to install these as well.  You can run `ElasticSearch` by typing from the command-line prompt:\n",
    "\n",
    "```\n",
    "$ <path_to_elasticsearch_bin>/elasticsearch &\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a few seconds (and a lot of logging) the database will be up and running; you may need to hit return for the prompt to show up. To test whether `ElasticSearch` is working execute the code in the cell below. __The database needs to be running throughout the execution of this script, otherwise you will get a connection error.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b'{\\n  \"name\" : \"DESKTOP-QNOM0EQ\",\\n  \"cluster_name\" : \"elasticsearch\",\\n  \"c'\n",
      " b'luster_uuid\" : \"eig_fG5ySRWEscM_Y6LUcQ\",\\n  \"version\" : {\\n    \"number\" : '\n",
      " b'\"8.10.2\",\\n    \"build_flavor\" : \"default\",\\n    \"build_type\" : \"zip\",\\n    '\n",
      " b'\"build_hash\" : \"6d20dd8ce62365be9b1aca96427de4622e970e9e\",\\n    \"build_da'\n",
      " b'te\" : \"2023-09-19T08:16:24.564900370Z\",\\n    \"build_snapshot\" : false,\\n  '\n",
      " b'  \"lucene_version\" : \"9.7.0\",\\n    \"minimum_wire_compatibility_version\" :'\n",
      " b' \"7.17.0\",\\n    \"minimum_index_compatibility_version\" : \"7.0.0\"\\n  },\\n  \"t'\n",
      " b'agline\" : \"You Know, for Search\"\\n}\\n')\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "try:\n",
    "    resp = requests.get('http://localhost:9200/')\n",
    "    pprint(resp.content)\n",
    "    \n",
    "except Exception:\n",
    "    print('elasticsearch is not running')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `ElasticSearch` is working you will see an answer from the server; otherwise you will see a message indicating that it is not running. You can try also throwing the URL http://localhost:9200 to your browser; you should get a similar answer.\n",
    "\n",
    "**In version 8 they introduced enhanced security, which may give you trouble when executing the code here, to deal with this you can either install an earlier version (7 or older) or turn off security settings in their `config/elasticsearch.yml` config file (just set to _false_ everything concerning the security options).** Since we are using the database in offline, local mode this should not be a problem.\n",
    "\n",
    "Also, you should run this script locally in your machine, if you use Google Collab or similar this is not going to work because elasticsearch should be running on the machine where the script is being executed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Indexing and querying\n",
    "\n",
    "`ElasticSearch` is a database that allows storing documents (tables do not need a predefined schema as in relational databases). Text in these documents can be processed so the queries extend beyond exact matches allowing complex queries, fuzzy matching and ranking documents respect to the actual match. \n",
    "\n",
    "These kinds of databases are behind search engines like Google Search or Bing.\n",
    "\n",
    "There are different ways of operating with ElasticSearch. It is deployed esentially as a web service with a REST API, so it can be accessed basically from any language with a library for operating with HTTP servers.\n",
    "\n",
    "We are going to use two python libraries for programming on top of ElasticSearch: `elasticsearch` and `elasticsearch-dsl`. Both provide access to ElasticSearch functionalities hiding and making more programming-friendly the interactions, the second one is more convenient for configurating and searching. Make sure both python libraries are installed to proceed with this session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only going to see the essential elements for developing the session but feel free to learn more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To interact with ElasticSearch with need a client object of type `Elasticsearch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carlos Arbonés\\AppData\\Local\\Temp\\ipykernel_4800\\2120730465.py:3: DeprecationWarning: The 'timeout' parameter is deprecated in favor of 'request_timeout'\n",
      "  client = Elasticsearch(\"http://localhost:9200\", timeout=1000)\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "client = Elasticsearch(\"http://localhost:9200\", timeout=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this client you have a connection for operating with Elastic search. Now we will create an index. There are index operations in each library, but the one in `elasticseach-dsl` is simpler to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch_dsl import Index\n",
    "\n",
    "index = Index('test', using=client)  # if it does not exist, it is created; if it does exist, then it connects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will need some text to index, for testing purposes we are going to use the python library `loremipsum`. We will need to install it first if it is not installed already, uncomment the code in next cell if you need to install the library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create some random paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "('Dolor aliquam modi quaerat porro quaerat porro. Consectetur ipsum voluptatem '\n",
      " 'amet etincidunt magnam eius eius. Magnam aliquam est porro labore sed amet. '\n",
      " 'Aliquam etincidunt adipisci velit porro consectetur velit. Ipsum dolor sit '\n",
      " 'labore aliquam. Consectetur quisquam est amet. Ipsum magnam numquam tempora '\n",
      " 'non tempora porro.')\n"
     ]
    }
   ],
   "source": [
    "import lorem\n",
    "\n",
    "texts = [lorem.paragraph() for _ in range(10)]\n",
    "print(len(texts))\n",
    "pprint(texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can index the paragraphs in ElasticSearch using the `index` method. The document is passed as a python dictionary with the `document` parameter. The keys of the dictionary will be the fields of the document, in this case we well have only one (`text`) -- here, we use this tag but could use anything we wanted to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing new text: Dolor aliquam modi quaerat porro quaerat porro. Consectetur ipsum volu ...\n",
      "Indexing new text: Tempora porro magnam adipisci quisquam amet consectetur. Quaerat conse ...\n",
      "Indexing new text: Numquam eius sed porro amet dolor amet. Neque dolor tempora dolore dol ...\n",
      "Indexing new text: Dolor ut quaerat dolorem non quiquia voluptatem amet. Ipsum magnam mag ...\n",
      "Indexing new text: Neque ut eius voluptatem est. Dolor dolorem dolorem labore voluptatem  ...\n",
      "Indexing new text: Quaerat modi quaerat amet quisquam adipisci magnam dolore. Quaerat tem ...\n",
      "Indexing new text: Neque amet dolore modi tempora. Etincidunt numquam labore est. Amet co ...\n",
      "Indexing new text: Sed modi est consectetur neque quisquam consectetur non. Eius ipsum ve ...\n",
      "Indexing new text: Adipisci ut modi dolor ipsum consectetur. Tempora amet tempora neque.  ...\n",
      "Indexing new text: Eius neque modi neque dolore modi. Neque eius velit quiquia ut. Dolore ...\n"
     ]
    }
   ],
   "source": [
    "for t in texts:\n",
    "    client.index(index='test', document={'text': t})\n",
    "    print(f'Indexing new text: {t[:70]} ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case we want to get all docs in the index, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 50 hits:\n",
      "{'text': 'Magnam etincidunt ipsum voluptatem ipsum quaerat dolorem. Numquam '\n",
      "         'dolor eius aliquam porro non. Dolore tempora numquam velit amet est '\n",
      "         'dolor dolore. Quiquia adipisci aliquam ut non ut. Numquam neque '\n",
      "         'etincidunt etincidunt adipisci. Dolore tempora ipsum quisquam amet '\n",
      "         'neque. Magnam numquam amet voluptatem. Consectetur quiquia non '\n",
      "         'consectetur ut velit modi. Dolorem ut ipsum dolor.'}\n",
      "{'text': 'Ut dolore sed etincidunt. Magnam adipisci adipisci magnam dolor '\n",
      "         'porro. Etincidunt consectetur porro quaerat sit neque dolore '\n",
      "         'consectetur. Sed neque consectetur amet ut. Sit dolore modi labore '\n",
      "         'sed.'}\n",
      "{'text': 'Quaerat non eius adipisci labore. Labore ipsum modi numquam ut. '\n",
      "         'Adipisci amet ipsum tempora dolorem porro. Ut amet voluptatem magnam '\n",
      "         'consectetur non. Sed consectetur adipisci eius ipsum dolore est. '\n",
      "         'Eius dolore ipsum dolor ut quaerat dolore. Quisquam ipsum labore sed '\n",
      "         'voluptatem eius dolore eius.'}\n",
      "{'text': 'Amet numquam numquam consectetur amet. Etincidunt quaerat ut porro '\n",
      "         'voluptatem eius. Quisquam amet aliquam non quaerat est. Neque '\n",
      "         'quisquam sit aliquam. Quaerat dolore velit sed. Numquam sed '\n",
      "         'voluptatem quiquia eius. Eius sed ipsum tempora labore ipsum tempora '\n",
      "         'tempora. Velit tempora magnam aliquam sit quiquia ipsum.'}\n",
      "{'text': 'Amet dolorem amet tempora adipisci. Sed dolore dolore voluptatem '\n",
      "         'modi labore. Ut quisquam dolor quisquam neque. Est tempora sit ut '\n",
      "         'non est etincidunt dolor. Porro est sed consectetur. Consectetur '\n",
      "         'dolor ipsum eius velit. Quaerat quiquia non consectetur labore '\n",
      "         'labore. Ipsum etincidunt quisquam ut ut adipisci sit labore. Dolorem '\n",
      "         'sit amet ipsum adipisci velit.'}\n",
      "{'text': 'Adipisci magnam dolor neque porro adipisci voluptatem. Quaerat sed '\n",
      "         'ut quaerat. Sit quisquam numquam quisquam consectetur. Sit numquam '\n",
      "         'consectetur quiquia tempora. Dolorem eius labore labore aliquam '\n",
      "         'aliquam adipisci ut. Aliquam velit velit etincidunt porro neque '\n",
      "         'dolorem. Magnam aliquam adipisci quaerat dolor.'}\n",
      "{'text': 'Amet quisquam numquam amet neque eius ut labore. Aliquam sed tempora '\n",
      "         'amet quiquia magnam. Eius neque sed modi dolor. Quisquam porro sed '\n",
      "         'quiquia. Ut modi est sit aliquam neque eius dolorem. Quiquia eius '\n",
      "         'sed consectetur etincidunt etincidunt quisquam dolore. Non porro '\n",
      "         'adipisci etincidunt ut dolore magnam adipisci. Consectetur sed non '\n",
      "         'eius dolor adipisci amet velit. Numquam ipsum velit etincidunt eius. '\n",
      "         'Modi consectetur quisquam quaerat velit.'}\n",
      "{'text': 'Modi ut magnam porro adipisci non amet velit. Dolor quaerat aliquam '\n",
      "         'magnam. Quisquam magnam velit amet quaerat est eius quiquia. Aliquam '\n",
      "         'adipisci sit etincidunt. Quisquam tempora labore eius.'}\n",
      "{'text': 'Adipisci voluptatem etincidunt quaerat quaerat. Dolore sit numquam '\n",
      "         'est quiquia velit dolorem tempora. Ipsum ipsum dolorem numquam '\n",
      "         'magnam dolorem. Sed dolorem ut ut tempora est. Aliquam amet tempora '\n",
      "         'consectetur. Magnam sit dolor eius tempora non neque. Quaerat '\n",
      "         'dolorem aliquam numquam. Quiquia magnam numquam modi dolorem '\n",
      "         'aliquam. Etincidunt labore sit adipisci adipisci tempora dolor '\n",
      "         'neque. Dolor dolore quaerat tempora neque etincidunt ut dolore.'}\n",
      "{'text': 'Est ut etincidunt quaerat. Dolor est magnam dolor neque dolorem. '\n",
      "         'Ipsum ipsum tempora adipisci eius aliquam consectetur quaerat. '\n",
      "         'Dolore sit est tempora non voluptatem dolorem. Eius consectetur '\n",
      "         'consectetur ipsum dolore neque magnam. Dolor labore porro numquam '\n",
      "         'adipisci magnam labore. Magnam neque aliquam amet. Quaerat porro '\n",
      "         'dolore sed. Sit velit voluptatem magnam.'}\n"
     ]
    }
   ],
   "source": [
    "# get all docs in index 'test'\n",
    "resp = client.search(index=\"test\", query={\"match_all\": {}})\n",
    "\n",
    "# print them\n",
    "print(f\"Got {resp['hits']['total']['value']} hits:\")\n",
    "for hit in resp['hits']['hits']:\n",
    "    pprint(hit[\"_source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also search for documents that contain a given keyword:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 matches.\n",
      "\n",
      "ID: 47DF74oBTWYgklMH0QF5\n",
      "Text: Non ut non dolor. Quiquia ipsum quiquia quaerat quisquam. Sit sed labore ut modi consectetur quiquia. Velit modi tempora dolorem dolorem magnam sed porro. Etincidunt eius quiquia non est aliquam ipsum. Dolor tempora neque ut dolor magnam. Etincidunt est aliquam quisquam neque non adipisci velit. Neque labore modi sit non est dolorem non.\n",
      "\n",
      "ID: -bDI74oBTWYgklMHbgEM\n",
      "Text: Non etincidunt dolore dolor. Non porro quisquam quiquia. Consectetur eius eius etincidunt dolor. Dolorem eius non dolorem numquam dolor. Porro non consectetur voluptatem modi dolor. Etincidunt eius consectetur modi quisquam magnam eius tempora. Quiquia etincidunt magnam aliquam neque consectetur quiquia dolore.\n",
      "\n",
      "ID: 37DF74oBTWYgklMH0QE4\n",
      "Text: Numquam voluptatem numquam dolorem. Dolor labore consectetur etincidunt. Sit quisquam non dolor amet adipisci. Eius ut est aliquam voluptatem consectetur. Quiquia voluptatem non etincidunt labore non dolorem. Ut dolorem modi est aliquam tempora sed amet.\n",
      "\n",
      "ID: CLDN74oBTWYgklMHNwJv\n",
      "Text: Ipsum dolor consectetur dolor consectetur consectetur. Velit dolore ipsum magnam quiquia quisquam modi quiquia. Quaerat non sed quiquia porro. Non sed sit magnam quisquam. Non adipisci amet tempora est porro labore dolore. Sed amet amet neque. Sed dolor quaerat quisquam est eius magnam. Numquam neque numquam eius dolorem tempora tempora adipisci. Consectetur dolore quiquia etincidunt neque non. Magnam quaerat magnam sed quisquam ipsum.\n",
      "\n",
      "ID: -LDI74oBTWYgklMHbgEE\n",
      "Text: Velit neque aliquam quisquam etincidunt. Sed velit dolore quaerat tempora adipisci. Non est quisquam quisquam. Ut velit dolorem porro numquam sit. Dolorem est quiquia neque non sit.\n",
      "\n",
      "ID: K2-W74oBgkzt8pv6sy-0\n",
      "Text: Magnam etincidunt ipsum voluptatem ipsum quaerat dolorem. Numquam dolor eius aliquam porro non. Dolore tempora numquam velit amet est dolor dolore. Quiquia adipisci aliquam ut non ut. Numquam neque etincidunt etincidunt adipisci. Dolore tempora ipsum quisquam amet neque. Magnam numquam amet voluptatem. Consectetur quiquia non consectetur ut velit modi. Dolorem ut ipsum dolor.\n",
      "\n",
      "ID: DbDN74oBTWYgklMHNwKP\n",
      "Text: Ut velit numquam porro tempora labore est quaerat. Amet aliquam neque quiquia magnam. Sit quisquam non dolorem aliquam consectetur. Est dolorem tempora quisquam non. Ipsum sit dolor neque amet ut.\n",
      "\n",
      "ID: DLDN74oBTWYgklMHNwKH\n",
      "Text: Porro porro tempora eius. Dolorem neque voluptatem eius ipsum magnam neque. Consectetur velit adipisci ipsum. Sit velit sit dolore. Non labore voluptatem velit labore dolorem modi. Non quaerat porro adipisci dolor quisquam aliquam voluptatem. Neque modi velit labore aliquam neque. Ipsum dolorem quisquam tempora sed numquam amet. Dolorem amet sit non velit quiquia adipisci sed. Ut quisquam etincidunt adipisci sit.\n",
      "\n",
      "ID: ELDN74oBTWYgklMHNwKv\n",
      "Text: Dolorem quiquia neque ut consectetur tempora. Ipsum tempora velit ipsum ipsum est eius. Dolor quaerat sit ut labore quisquam consectetur non. Porro quiquia consectetur adipisci quisquam porro. Amet adipisci amet neque consectetur quiquia. Labore adipisci etincidunt magnam. Dolorem sit non modi consectetur magnam quiquia. Magnam ut ut porro quaerat amet. Labore quaerat quaerat non voluptatem quiquia eius adipisci. Quaerat magnam magnam adipisci.\n",
      "\n",
      "ID: 1rDB74oBTWYgklMHmQEa\n",
      "Text: Ipsum magnam labore modi numquam. Modi aliquam ut quiquia adipisci voluptatem neque velit. Velit modi dolorem sed voluptatem quisquam eius ipsum. Labore consectetur neque non porro labore. Adipisci voluptatem voluptatem sed eius tempora non numquam.\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch_dsl import Search\n",
    "\n",
    "# the following search query specifies the field where we want to search\n",
    "s_obj = Search(using=client, index='test')\n",
    "sq = s_obj.query('match', text='non')\n",
    "resp = sq.execute()\n",
    "\n",
    "print(f'Found {len(resp)} matches.')\n",
    "\n",
    "for hit in resp:\n",
    "    print(f'\\nID: {hit.meta.id}\\nText: {hit.text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Counting words and docs\n",
    "\n",
    "`Elastic search` helps us to obtain the counts of words in each document. For example, the following code obtains the counts of words of a whole index by adding the counts of words obtained from each document through the functionality of `termvectors`. This function also allows us to get _document counts_ for computing tf-idf weights, by setting the `term_statistics` option to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch.helpers import scan\n",
    "from collections import Counter\n",
    "\n",
    "# Search for all the documents and query the list of (word, frequency) of each one\n",
    "# Totals are accumulated using a Counter for term frequencies, but not for document freqs.\n",
    "word_counts = Counter()\n",
    "doc_counts = Counter()\n",
    "sc = scan(client, index='test', query={\"query\" : {\"match_all\": {}}})\n",
    "for s in sc:\n",
    "    tv = client.termvectors(index='test', id=s['_id'], fields=['text'], term_statistics=True, positions=False)\n",
    "    if 'text' in tv['term_vectors']:   # just in case some document has no field named 'text'\n",
    "        for t in tv['term_vectors']['text']['terms']:\n",
    "            word = t\n",
    "            count = tv['term_vectors']['text']['terms'][t]['term_freq']\n",
    "            df = tv['term_vectors']['text']['terms'][t]['doc_freq']\n",
    "            #pprint(tv['term_vectors']['text']['terms'][t])\n",
    "            word_counts.update({word: count})  # número de veces que aparece la palabra en el documento\n",
    "            doc_counts[word] = df      # número de documentos en los que aparece la palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('adipisci', 115),\n",
       " ('consectetur', 110),\n",
       " ('quaerat', 106),\n",
       " ('ut', 102),\n",
       " ('quisquam', 98),\n",
       " ('magnam', 96),\n",
       " ('neque', 92),\n",
       " ('dolore', 91),\n",
       " ('dolor', 90),\n",
       " ('dolorem', 90),\n",
       " ('tempora', 90),\n",
       " ('amet', 87),\n",
       " ('eius', 87),\n",
       " ('quiquia', 87),\n",
       " ('porro', 86),\n",
       " ('velit', 86),\n",
       " ('numquam', 85),\n",
       " ('modi', 83),\n",
       " ('non', 81),\n",
       " ('labore', 81),\n",
       " ('sed', 80),\n",
       " ('ipsum', 79),\n",
       " ('aliquam', 78),\n",
       " ('sit', 78),\n",
       " ('est', 76),\n",
       " ('voluptatem', 76),\n",
       " ('etincidunt', 72)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show word frequencies\n",
    "word_counts.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('quaerat', 46),\n",
       " ('adipisci', 45),\n",
       " ('tempora', 45),\n",
       " ('consectetur', 44),\n",
       " ('modi', 44),\n",
       " ('non', 44),\n",
       " ('quisquam', 43),\n",
       " ('dolorem', 42),\n",
       " ('neque', 42),\n",
       " ('eius', 41),\n",
       " ('ut', 41),\n",
       " ('labore', 41),\n",
       " ('amet', 40),\n",
       " ('dolor', 40),\n",
       " ('porro', 40),\n",
       " ('velit', 40),\n",
       " ('sit', 40),\n",
       " ('aliquam', 39),\n",
       " ('magnam', 39),\n",
       " ('numquam', 39),\n",
       " ('quiquia', 39),\n",
       " ('voluptatem', 39),\n",
       " ('dolore', 38),\n",
       " ('ipsum', 38),\n",
       " ('est', 37),\n",
       " ('etincidunt', 37),\n",
       " ('sed', 34)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show doc freq\n",
    "doc_counts.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Proposed simple exercise\n",
    "\n",
    "To get more familiar with elasticsearch, we propose that you _generate the Boolean and tf-idf matrices_ for the toy example that we used in class. You will find 7 text documents that contain the toy documents with the materials for this session in the racó. The steps to follow are:\n",
    "\n",
    "- create an empty index\n",
    "- open each text document in the `toy-docs` folder provided, read its contents and add it to the index as a new document; your index should contain 7 documents after this\n",
    "- use the `termvectors` function to obtain term and doc counts, generate Boolean and tf-idf matrices based on these counts\n",
    "- double check that your results coincide with the numbers in theory slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch_dsl import Index\n",
    "\n",
    "index = Index('exercise', using=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 8):\n",
    "    with open('toy-docs/' + f'd{i}.txt', 'r') as f:\n",
    "        text = f.read()\n",
    "        client.index(index='exercise', document={'text': text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 0 hits\n"
     ]
    }
   ],
   "source": [
    "resp = client.search(index=\"exercise\", query={\"match_all\": {}})\n",
    "print(f\"Got {resp['hits']['total']['value']} hits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[0, 0, 1, 0, 1, 0],\n",
      "       [0, 0, 0, 0, 1, 1],\n",
      "       [1, 1, 1, 0, 1, 0],\n",
      "       [0, 0, 1, 1, 1, 1],\n",
      "       [0, 1, 0, 1, 1, 0],\n",
      "       [0, 0, 0, 1, 1, 0],\n",
      "       [1, 1, 0, 0, 0, 0]])\n",
      "array([[0.        , 0.        , 0.84729786, 0.        , 0.15415068,\n",
      "        0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.        , 0.07707534,\n",
      "        1.25276297],\n",
      "       [1.25276297, 0.28243262, 0.28243262, 0.        , 0.05138356,\n",
      "        0.        ],\n",
      "       [0.        , 0.        , 0.28243262, 0.56486524, 0.03853767,\n",
      "        0.83517531],\n",
      "       [0.        , 0.42364893, 0.        , 0.14121631, 0.02569178,\n",
      "        0.        ],\n",
      "       [0.        , 0.        , 0.        , 0.28243262, 0.0578065 ,\n",
      "        0.        ],\n",
      "       [0.15659537, 0.10591223, 0.        , 0.        , 0.        ,\n",
      "        0.        ]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "boolean_matrix = np.zeros((7, 6), dtype=int)\n",
    "vector_matrix = np.zeros((7, 6))\n",
    "map = {'five': 0, 'four': 1, 'one': 2, 'six': 3, 'three': 4, 'two': 5}\t\n",
    "\n",
    "word_counts = Counter()\n",
    "doc_counts = Counter()\n",
    "sc = scan(client, index='exercise', query={\"query\" : {\"match_all\": {}}})\n",
    "for i, s in enumerate(sc):\n",
    "    tv = client.termvectors(index='exercise', \n",
    "                            id=s['_id'], \n",
    "                            fields=['text'], \n",
    "                            term_statistics=True, \n",
    "                            positions=False)\n",
    "    \n",
    "    if 'text' in tv['term_vectors']:   \n",
    "        for t in tv['term_vectors']['text']['terms']:\n",
    "            word = t\n",
    "            count = tv['term_vectors']['text']['terms'][t]['term_freq']\n",
    "            df = tv['term_vectors']['text']['terms'][t]['doc_freq']\n",
    "            word_counts.update({word: count})  \n",
    "            doc_counts[word] = df  \n",
    "            \n",
    "            boolean_matrix[i][map[word]] = 1\n",
    "            vector_matrix[i][map[word]] = count/max(word_counts.values())*np.log(7/df)\n",
    "            \n",
    "pprint(boolean_matrix) \n",
    "pprint(vector_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cleanup\n",
    "\n",
    "Finally, we remove the test index.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {
    "height": "135px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
