{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAI Lab Session 2: Intro to ElasticSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session you will learn:\n",
    "\n",
    "- a few basics of the `ElasticSearch` database\n",
    "- how to index a set of documents and how to ask simple queries about these documents\n",
    "- how to do this from `Python`\n",
    "- based on the previous, you will compute the boolean and tf-idf matrix for the toy corpus used in class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ElasticSearch\n",
    "\n",
    "[ElasticSearch](https://www.elastic.co/) is a _NoSQL/document_ database with the capability of indexing and searching text documents. As a rough analogue, we can use the following table for the equivalence between ElasticSearch and a more classical relational database:\n",
    "\n",
    "| Relational DB | ElasticSearch |\n",
    "|---|---|\n",
    "| Database | Index |\n",
    "| Table | Type |\n",
    "| Row / record | Document |\n",
    "| Column | Field |\n",
    "\n",
    "An index can be thought of as an optimized collection of documents and each document is a collection of fields, which are the key-value pairs that contain your data.\n",
    "\n",
    "`ElasticSearch` is a pretty big beast with many options. Luckily, there is much documentation, a few useful links are:\n",
    "\n",
    "- Here is the [full documentation](https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html)\n",
    "- Intros you may want to have a look at: \n",
    "    - https://medium.com/expedia-group-tech/getting-started-with-elastic-search-6af62d7df8dd\n",
    "    - http://joelabrahamsson.com/elasticsearch-101\n",
    "- You found another one that you liked? Let us know. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Running ElasticSearch\n",
    "\n",
    "First you will need to install `ElasticSearch` following instructions in their [documentation](https://www.elastic.co/guide/en/elasticsearch/reference/current/install-elasticsearch.html).\n",
    "\n",
    "This database runs as a web service in a machine and can be accessed using a REST web API; however we will interact with the database through its python libraries `elasticsearch-py` and `elasticsearch-dsl`, so you will need to install these as well.  You can run `ElasticSearch` by typing from the command-line prompt:\n",
    "\n",
    "```\n",
    "$ <path_to_elasticsearch_bin>/elasticsearch &\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a few seconds (and a lot of logging) the database will be up and running; you may need to hit return for the prompt to show up. To test whether `ElasticSearch` is working execute the code in the cell below. __The database needs to be running throughout the execution of this script, otherwise you will get a connection error.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b'{\\n  \"name\" : \"10-192-241-239client.eduroam.upc.edu\",\\n  \"cluster_name\" : '\n",
      " b'\"elasticsearch\",\\n  \"cluster_uuid\" : \"pwjGBM8RSCyrLYRBgGJxRQ\",\\n  \"version'\n",
      " b'\" : {\\n    \"number\" : \"8.9.2\",\\n    \"build_flavor\" : \"default\",\\n    \"build'\n",
      " b'_type\" : \"tar\",\\n    \"build_hash\" : \"e8179018838f55b8820685f92e245abef3bd'\n",
      " b'dc0f\",\\n    \"build_date\" : \"2023-08-31T02:43:14.210479707Z\",\\n    \"build_s'\n",
      " b'napshot\" : false,\\n    \"lucene_version\" : \"9.7.0\",\\n    \"minimum_wire_comp'\n",
      " b'atibility_version\" : \"7.17.0\",\\n    \"minimum_index_compatibility_version\"'\n",
      " b' : \"7.0.0\"\\n  },\\n  \"tagline\" : \"You Know, for Search\"\\n}\\n')\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "try:\n",
    "    resp = requests.get('http://localhost:9200/')\n",
    "    pprint(resp.content)\n",
    "    \n",
    "except Exception:\n",
    "    print('elasticsearch is not running')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `ElasticSearch` is working you will see an answer from the server; otherwise you will see a message indicating that it is not running. You can try also throwing the URL http://localhost:9200 to your browser; you should get a similar answer.\n",
    "\n",
    "**In version 8 they introduced enhanced security, which may give you trouble when executing the code here, to deal with this you can either install an earlier version (7 or older) or turn off security settings in their `config/elasticsearch.yml` config file (just set to _false_ everything concerning the security options).** Since we are using the database in offline, local mode this should not be a problem.\n",
    "\n",
    "Also, you should run this script locally in your machine, if you use Google Collab or similar this is not going to work because elasticsearch should be running on the machine where the script is being executed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Indexing and querying\n",
    "\n",
    "`ElasticSearch` is a database that allows storing documents (tables do not need a predefined schema as in relational databases). Text in these documents can be processed so the queries extend beyond exact matches allowing complex queries, fuzzy matching and ranking documents respect to the actual match. \n",
    "\n",
    "These kinds of databases are behind search engines like Google Search or Bing.\n",
    "\n",
    "There are different ways of operating with ElasticSearch. It is deployed esentially as a web service with a REST API, so it can be accessed basically from any language with a library for operating with HTTP servers.\n",
    "\n",
    "We are going to use two python libraries for programming on top of ElasticSearch: `elasticsearch` and `elasticsearch-dsl`. Both provide access to ElasticSearch functionalities hiding and making more programming-friendly the interactions, the second one is more convenient for configurating and searching. Make sure both python libraries are installed to proceed with this session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: elasticsearch in /Users/marias/.local/lib/python3.10/site-packages (8.9.0)\n",
      "Requirement already satisfied: elastic-transport<9,>=8 in /Users/marias/.local/lib/python3.10/site-packages (from elasticsearch) (8.4.0)\n",
      "Requirement already satisfied: urllib3<2,>=1.26.2 in /Users/marias/anaconda3/lib/python3.10/site-packages (from elastic-transport<9,>=8->elasticsearch) (1.26.14)\n",
      "Requirement already satisfied: certifi in /Users/marias/anaconda3/lib/python3.10/site-packages (from elastic-transport<9,>=8->elasticsearch) (2022.12.7)\n",
      "Requirement already satisfied: elasticsearch-dsl in /Users/marias/.local/lib/python3.10/site-packages (8.9.0)\n",
      "Requirement already satisfied: elasticsearch<9.0.0,>=8.0.0 in /Users/marias/.local/lib/python3.10/site-packages (from elasticsearch-dsl) (8.9.0)\n",
      "Requirement already satisfied: python-dateutil in /Users/marias/anaconda3/lib/python3.10/site-packages (from elasticsearch-dsl) (2.8.2)\n",
      "Requirement already satisfied: elastic-transport<9,>=8 in /Users/marias/.local/lib/python3.10/site-packages (from elasticsearch<9.0.0,>=8.0.0->elasticsearch-dsl) (8.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/marias/anaconda3/lib/python3.10/site-packages (from python-dateutil->elasticsearch-dsl) (1.16.0)\n",
      "Requirement already satisfied: certifi in /Users/marias/anaconda3/lib/python3.10/site-packages (from elastic-transport<9,>=8->elasticsearch<9.0.0,>=8.0.0->elasticsearch-dsl) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<2,>=1.26.2 in /Users/marias/anaconda3/lib/python3.10/site-packages (from elastic-transport<9,>=8->elasticsearch<9.0.0,>=8.0.0->elasticsearch-dsl) (1.26.14)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install elasticsearch --user\n",
    "!pip3 install elasticsearch-dsl --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only going to see the essential elements for developing the session but feel free to learn more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To interact with ElasticSearch with need a client object of type `Elasticsearch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6b/9tcy3twj7w943d_3bplhtw100000gp/T/ipykernel_23194/2120730465.py:3: DeprecationWarning: The 'timeout' parameter is deprecated in favor of 'request_timeout'\n",
      "  client = Elasticsearch(\"http://localhost:9200\", timeout=1000)\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "client = Elasticsearch(\"http://localhost:9200\", timeout=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this client you have a connection for operating with Elastic search. Now we will create an index. There are index operations in each library, but the one in `elasticseach-dsl` is simpler to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch_dsl import Index\n",
    "\n",
    "index = Index('test', using=client)  # if it does not exist, it is created; if it does exist, then it connects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will need some text to index, for testing purposes we are going to use the python library `loremipsum`. We will need to install it first if it is not installed already, uncomment the code in next cell if you need to install the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lorem in /Users/marias/.local/lib/python3.10/site-packages (0.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install lorem --user  # Restart the kernel if you are not able to import the library in the next cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create some random paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Magnam labore amet dolore est quisquam amet adipisci. Numquam sed eius magnam. Tempora consectetur sed est neque modi aliquam labore. Dolor numquam eius sed voluptatem amet. Est neque ut numquam etincidunt. Eius aliquam consectetur ipsum eius amet. Ipsum quisquam porro modi eius. Eius est quisquam dolore dolore labore adipisci consectetur. Quiquia quisquam eius ipsum magnam sed ipsum.\n"
     ]
    }
   ],
   "source": [
    "import lorem\n",
    "\n",
    "texts = [lorem.paragraph() for _ in range(10)]\n",
    "print(len(texts))\n",
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can index the paragraphs in ElasticSearch using the `index` method. The document is passed as a python dictionary with the `document` parameter. The keys of the dictionary will be the fields of the document, in this case we well have only one (`text`) -- here, we use this tag but could use anything we wanted to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing new text: Magnam labore amet dolore est quisquam amet adipisci. Numquam sed eius ...\n",
      "Indexing new text: Consectetur etincidunt non magnam consectetur voluptatem eius. Quiquia ...\n",
      "Indexing new text: Ipsum consectetur velit sed ipsum numquam modi. Est labore non ipsum e ...\n",
      "Indexing new text: Velit sit sit est voluptatem est adipisci. Quiquia quisquam magnam sed ...\n",
      "Indexing new text: Numquam etincidunt magnam sed aliquam amet. Dolorem non labore quaerat ...\n",
      "Indexing new text: Velit ut numquam dolore sit dolorem quisquam. Sit consectetur neque ve ...\n",
      "Indexing new text: Numquam dolorem dolorem eius tempora. Sed non quisquam etincidunt sed  ...\n",
      "Indexing new text: Consectetur ut dolorem sed dolor labore velit. Ipsum velit ut aliquam. ...\n",
      "Indexing new text: Est numquam ut porro consectetur amet numquam. Sit labore aliquam quiq ...\n",
      "Indexing new text: Ut tempora quisquam ipsum consectetur numquam dolorem. Etincidunt numq ...\n"
     ]
    }
   ],
   "source": [
    "for t in texts:\n",
    "    client.index(index='test', document={'text': t})\n",
    "    print(f'Indexing new text: {t[:70]} ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case we want to get all docs in the index, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 10 hits:\n",
      "{'text': 'Magnam labore amet dolore est quisquam amet adipisci. Numquam sed '\n",
      "         'eius magnam. Tempora consectetur sed est neque modi aliquam labore. '\n",
      "         'Dolor numquam eius sed voluptatem amet. Est neque ut numquam '\n",
      "         'etincidunt. Eius aliquam consectetur ipsum eius amet. Ipsum quisquam '\n",
      "         'porro modi eius. Eius est quisquam dolore dolore labore adipisci '\n",
      "         'consectetur. Quiquia quisquam eius ipsum magnam sed ipsum.'}\n",
      "{'text': 'Consectetur etincidunt non magnam consectetur voluptatem eius. '\n",
      "         'Quiquia magnam sit dolore est quisquam. Sed voluptatem ipsum ut sed '\n",
      "         'porro. Sed ut velit dolore quaerat. Labore porro non consectetur. '\n",
      "         'Quaerat porro labore non quisquam amet sit numquam. Adipisci labore '\n",
      "         'amet magnam velit neque labore adipisci.'}\n",
      "{'text': 'Ipsum consectetur velit sed ipsum numquam modi. Est labore non ipsum '\n",
      "         'est. Sed dolorem porro neque ut ut adipisci. Modi consectetur amet '\n",
      "         'etincidunt. Quiquia tempora consectetur voluptatem sed porro sed '\n",
      "         'labore.'}\n",
      "{'text': 'Velit sit sit est voluptatem est adipisci. Quiquia quisquam magnam '\n",
      "         'sed sed adipisci. Consectetur velit neque dolorem. Dolorem '\n",
      "         'etincidunt dolor labore dolorem eius voluptatem. Est sit non sit est '\n",
      "         'quaerat ipsum dolorem. Aliquam porro etincidunt eius. Labore sed '\n",
      "         'amet dolorem. Numquam tempora quiquia eius. Ut consectetur magnam '\n",
      "         'ipsum numquam aliquam dolor velit.'}\n",
      "{'text': 'Numquam etincidunt magnam sed aliquam amet. Dolorem non labore '\n",
      "         'quaerat voluptatem. Est eius non dolorem consectetur voluptatem sed '\n",
      "         'sit. Modi quiquia ipsum neque labore velit ipsum etincidunt. Dolor '\n",
      "         'ut etincidunt magnam. Sit sed ipsum est modi. Consectetur ut eius '\n",
      "         'ut. Dolorem sit voluptatem neque.'}\n",
      "{'text': 'Velit ut numquam dolore sit dolorem quisquam. Sit consectetur neque '\n",
      "         'velit est consectetur non voluptatem. Ipsum dolorem dolorem '\n",
      "         'voluptatem amet velit numquam quaerat. Sed labore labore non. Ut '\n",
      "         'tempora etincidunt sed ipsum non modi consectetur.'}\n",
      "{'text': 'Numquam dolorem dolorem eius tempora. Sed non quisquam etincidunt '\n",
      "         'sed numquam. Ipsum sit quisquam etincidunt numquam quiquia labore '\n",
      "         'neque. Est dolore labore ipsum. Quisquam amet consectetur ut tempora '\n",
      "         'sit.'}\n",
      "{'text': 'Consectetur ut dolorem sed dolor labore velit. Ipsum velit ut '\n",
      "         'aliquam. Quisquam quisquam eius dolore. Est adipisci voluptatem '\n",
      "         'neque non dolore sed. Sed ut sit voluptatem consectetur quaerat '\n",
      "         'dolor non. Quisquam velit amet ut aliquam dolore consectetur. Labore '\n",
      "         'quisquam sit dolorem. Labore quiquia ipsum velit. Labore magnam amet '\n",
      "         'quiquia amet quiquia sit eius.'}\n",
      "{'text': 'Est numquam ut porro consectetur amet numquam. Sit labore aliquam '\n",
      "         'quiquia sit eius. Modi est modi labore. Sed dolor dolore eius '\n",
      "         'consectetur eius. Numquam adipisci voluptatem amet dolore quisquam '\n",
      "         'adipisci. Modi aliquam dolore quisquam quaerat ipsum ipsum. Aliquam '\n",
      "         'adipisci etincidunt dolor. Sit consectetur quisquam sed. Est dolore '\n",
      "         'sed magnam quiquia eius ut modi.'}\n",
      "{'text': 'Ut tempora quisquam ipsum consectetur numquam dolorem. Etincidunt '\n",
      "         'numquam quiquia aliquam dolorem. Amet adipisci voluptatem magnam. '\n",
      "         'Consectetur dolore quisquam magnam etincidunt consectetur. '\n",
      "         'Consectetur porro voluptatem aliquam dolor porro etincidunt amet. '\n",
      "         'Porro aliquam est consectetur eius ipsum ut etincidunt. Quisquam '\n",
      "         'tempora non quaerat neque etincidunt. Adipisci dolor magnam quaerat '\n",
      "         'eius aliquam. Magnam velit amet est amet.'}\n"
     ]
    }
   ],
   "source": [
    "# get all docs in index 'test'\n",
    "resp = client.search(index=\"test\", query={\"match_all\": {}})\n",
    "\n",
    "# print them\n",
    "print(f\"Got {resp['hits']['total']['value']} hits:\")\n",
    "for hit in resp['hits']['hits']:\n",
    "    pprint(hit[\"_source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also search for documents that contain a given keyword:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 matches.\n",
      "\n",
      "ID: 6GY1mIoB1aJZhB_GIOs0\n",
      "Text: Velit ut numquam dolore sit dolorem quisquam. Sit consectetur neque velit est consectetur non voluptatem. Ipsum dolorem dolorem voluptatem amet velit numquam quaerat. Sed labore labore non. Ut tempora etincidunt sed ipsum non modi consectetur.\n",
      "\n",
      "ID: 5GY1mIoB1aJZhB_GH-uq\n",
      "Text: Consectetur etincidunt non magnam consectetur voluptatem eius. Quiquia magnam sit dolore est quisquam. Sed voluptatem ipsum ut sed porro. Sed ut velit dolore quaerat. Labore porro non consectetur. Quaerat porro labore non quisquam amet sit numquam. Adipisci labore amet magnam velit neque labore adipisci.\n",
      "\n",
      "ID: 52Y1mIoB1aJZhB_GIOsS\n",
      "Text: Numquam etincidunt magnam sed aliquam amet. Dolorem non labore quaerat voluptatem. Est eius non dolorem consectetur voluptatem sed sit. Modi quiquia ipsum neque labore velit ipsum etincidunt. Dolor ut etincidunt magnam. Sit sed ipsum est modi. Consectetur ut eius ut. Dolorem sit voluptatem neque.\n",
      "\n",
      "ID: 6mY1mIoB1aJZhB_GIOt2\n",
      "Text: Consectetur ut dolorem sed dolor labore velit. Ipsum velit ut aliquam. Quisquam quisquam eius dolore. Est adipisci voluptatem neque non dolore sed. Sed ut sit voluptatem consectetur quaerat dolor non. Quisquam velit amet ut aliquam dolore consectetur. Labore quisquam sit dolorem. Labore quiquia ipsum velit. Labore magnam amet quiquia amet quiquia sit eius.\n",
      "\n",
      "ID: 6WY1mIoB1aJZhB_GIOtU\n",
      "Text: Numquam dolorem dolorem eius tempora. Sed non quisquam etincidunt sed numquam. Ipsum sit quisquam etincidunt numquam quiquia labore neque. Est dolore labore ipsum. Quisquam amet consectetur ut tempora sit.\n",
      "\n",
      "ID: 5WY1mIoB1aJZhB_GH-vJ\n",
      "Text: Ipsum consectetur velit sed ipsum numquam modi. Est labore non ipsum est. Sed dolorem porro neque ut ut adipisci. Modi consectetur amet etincidunt. Quiquia tempora consectetur voluptatem sed porro sed labore.\n",
      "\n",
      "ID: 5mY1mIoB1aJZhB_GH-vx\n",
      "Text: Velit sit sit est voluptatem est adipisci. Quiquia quisquam magnam sed sed adipisci. Consectetur velit neque dolorem. Dolorem etincidunt dolor labore dolorem eius voluptatem. Est sit non sit est quaerat ipsum dolorem. Aliquam porro etincidunt eius. Labore sed amet dolorem. Numquam tempora quiquia eius. Ut consectetur magnam ipsum numquam aliquam dolor velit.\n",
      "\n",
      "ID: 7GY1mIoB1aJZhB_GIOus\n",
      "Text: Ut tempora quisquam ipsum consectetur numquam dolorem. Etincidunt numquam quiquia aliquam dolorem. Amet adipisci voluptatem magnam. Consectetur dolore quisquam magnam etincidunt consectetur. Consectetur porro voluptatem aliquam dolor porro etincidunt amet. Porro aliquam est consectetur eius ipsum ut etincidunt. Quisquam tempora non quaerat neque etincidunt. Adipisci dolor magnam quaerat eius aliquam. Magnam velit amet est amet.\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch_dsl import Search\n",
    "\n",
    "# the following search query specifies the field where we want to search\n",
    "s_obj = Search(using=client, index='test')\n",
    "sq = s_obj.query('match', text='non')\n",
    "resp = sq.execute()\n",
    "\n",
    "print(f'Found {len(resp)} matches.')\n",
    "\n",
    "for hit in resp:\n",
    "    print(f'\\nID: {hit.meta.id}\\nText: {hit.text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Counting words and docs\n",
    "\n",
    "`Elastic search` helps us to obtain the counts of words in each document. For example, the following code obtains the counts of words of a whole index by adding the counts of words obtained from each document through the functionality of `termvectors`. This function also allows us to get _document counts_ for computing tf-idf weights, by setting the `term_statistics` option to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch.helpers import scan\n",
    "from collections import Counter\n",
    "\n",
    "# Search for all the documents and query the list of (word, frequency) of each one\n",
    "# Totals are accumulated using a Counter for term frequencies, but not for document freqs.\n",
    "word_counts = Counter()\n",
    "doc_counts = Counter()\n",
    "sc = scan(client, index='test', query={\"query\" : {\"match_all\": {}}})\n",
    "for s in sc:\n",
    "    tv = client.termvectors(index='test', id=s['_id'], fields=['text'], term_statistics=True, positions=False)\n",
    "    if 'text' in tv['term_vectors']:   # just in case some document has no field named 'text'\n",
    "        for t in tv['term_vectors']['text']['terms']:\n",
    "            word = t\n",
    "            count = tv['term_vectors']['text']['terms'][t]['term_freq']\n",
    "            df = tv['term_vectors']['text']['terms'][t]['doc_freq']\n",
    "            #pprint(tv['term_vectors']['text']['terms'][t])\n",
    "            word_counts.update({word: count})\n",
    "            doc_counts[word] = df      # the counts are not added to avoid overcounting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('consectetur', 28),\n",
       " ('sed', 27),\n",
       " ('ipsum', 23),\n",
       " ('labore', 23),\n",
       " ('eius', 22),\n",
       " ('est', 21),\n",
       " ('quisquam', 21),\n",
       " ('amet', 20),\n",
       " ('ut', 20),\n",
       " ('sit', 19),\n",
       " ('numquam', 18),\n",
       " ('dolorem', 18),\n",
       " ('etincidunt', 17),\n",
       " ('magnam', 16),\n",
       " ('voluptatem', 16),\n",
       " ('dolore', 15),\n",
       " ('velit', 15),\n",
       " ('aliquam', 14),\n",
       " ('non', 14),\n",
       " ('adipisci', 13),\n",
       " ('quiquia', 13),\n",
       " ('modi', 11),\n",
       " ('neque', 11),\n",
       " ('porro', 11),\n",
       " ('dolor', 10),\n",
       " ('quaerat', 9),\n",
       " ('tempora', 8)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show word frequencies\n",
    "word_counts.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('amet', 10),\n",
       " ('consectetur', 10),\n",
       " ('est', 10),\n",
       " ('ipsum', 10),\n",
       " ('ut', 10),\n",
       " ('etincidunt', 9),\n",
       " ('labore', 9),\n",
       " ('neque', 9),\n",
       " ('numquam', 9),\n",
       " ('quiquia', 9),\n",
       " ('sed', 9),\n",
       " ('voluptatem', 9),\n",
       " ('eius', 8),\n",
       " ('quisquam', 8),\n",
       " ('non', 8),\n",
       " ('adipisci', 7),\n",
       " ('dolore', 7),\n",
       " ('magnam', 7),\n",
       " ('quaerat', 7),\n",
       " ('sit', 7),\n",
       " ('velit', 7),\n",
       " ('dolorem', 7),\n",
       " ('aliquam', 6),\n",
       " ('dolor', 6),\n",
       " ('porro', 6),\n",
       " ('tempora', 6),\n",
       " ('modi', 5)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show doc freq\n",
    "doc_counts.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Proposed simple exercise\n",
    "\n",
    "To get more familiar with elasticsearch, we propose that you _generate the Boolean and tf-idf matrices_ for the toy example that we used in class. You will find 7 text documents that contain the toy documents with the materials for this session in the rac√≥. The steps to follow are:\n",
    "\n",
    "- create an empty index\n",
    "- open each text document in the `toy-docs` folder provided, read its contents and add it to the index as a new document; your index should contain 7 documents after this\n",
    "- use the `termvectors` function to obtain term and doc counts, generate Boolean and tf-idf matrices based on these counts\n",
    "- double check that your results coincide with the numbers in theory slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cleanup\n",
    "\n",
    "Finally, we remove the test index.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {
    "height": "135px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
